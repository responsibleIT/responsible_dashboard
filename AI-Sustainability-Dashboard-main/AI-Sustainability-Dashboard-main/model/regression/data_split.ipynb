{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3a4a06b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split # Still useful for shuffling and initial split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3ece79d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Configuration ---\n",
    "BASE_DATA_PATH = Path(\"../data-generation/spam/runs\")\n",
    "OUTPUT_DATA_PATH = Path(\"data_split\")\n",
    "\n",
    "COLUMNS = ['threshold', 'flops', 'non_zero_params', 'params_reduction_pct', 'flops_reduction_pct', 'overall_accuracy']\n",
    "THRESHOLDS = np.round(np.arange(0, 10.1, 0.1), 1)\n",
    "\n",
    "N_VALIDATION_MODELS = 2\n",
    "N_TEST_MODELS = 2\n",
    "\n",
    "RANDOM_STATE = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "158fb294",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading and combining CSVs...\n",
      "Combined 17 CSVs. Total rows: 1717\n",
      "Number of unique model_ids: 17\n"
     ]
    }
   ],
   "source": [
    "# --- 1. Load and Combine All CSVs with a 'model_id' ---\n",
    "print(\"\\nLoading and combining CSVs...\")\n",
    "all_dfs = []\n",
    "model_id_counter = 0\n",
    "for csv_file in BASE_DATA_PATH.rglob(\"pruning_results.csv\"):\n",
    "    try:\n",
    "        df = pd.read_csv(csv_file); df['model_id'] = model_id_counter\n",
    "        all_dfs.append(df); model_id_counter += 1\n",
    "    except Exception as e: print(f\"Error reading {csv_file}: {e}\")\n",
    "\n",
    "if not all_dfs: raise ValueError(f\"No CSV files found or loaded from {BASE_DATA_PATH}.\")\n",
    "combined_df = pd.concat(all_dfs, ignore_index=True)\n",
    "print(f\"Combined {len(all_dfs)} CSVs. Total rows: {len(combined_df)}\")\n",
    "print(f\"Number of unique model_ids: {combined_df['model_id'].nunique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "58c4a158",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Performing model-aware train-validation-test split with fixed counts...\n",
      "Number of models for Training: 13\n",
      "Number of models for Validation: 2\n",
      "Number of models for Testing: 2\n",
      "\n",
      "Shape of Training DataFrame: (1313, 18)\n",
      "Shape of Validation DataFrame: (202, 18)\n",
      "Shape of Test DataFrame: (202, 18)\n"
     ]
    }
   ],
   "source": [
    "# --- 2. Perform Model-Aware Train-Validation-Test Split with Fixed Counts ---\n",
    "print(\"\\nPerforming model-aware train-validation-test split with fixed counts...\")\n",
    "unique_model_ids = combined_df['model_id'].unique()\n",
    "np.random.seed(RANDOM_STATE) # for reproducibility of np.random.choice\n",
    "np.random.shuffle(unique_model_ids) # Shuffle IDs randomly\n",
    "\n",
    "if len(unique_model_ids) < (N_VALIDATION_MODELS + N_TEST_MODELS):\n",
    "    raise ValueError(\n",
    "        f\"Not enough unique models ({len(unique_model_ids)}) to satisfy \"\n",
    "        f\"{N_VALIDATION_MODELS} for validation and {N_TEST_MODELS} for testing. \"\n",
    "        f\"Need at least {N_VALIDATION_MODELS + N_TEST_MODELS} models.\"\n",
    "    )\n",
    "\n",
    "# Select test model IDs\n",
    "test_model_ids = unique_model_ids[:N_TEST_MODELS]\n",
    "remaining_ids_after_test = unique_model_ids[N_TEST_MODELS:]\n",
    "\n",
    "if len(remaining_ids_after_test) < N_VALIDATION_MODELS:\n",
    "     raise ValueError(\n",
    "        f\"Not enough unique models remaining ({len(remaining_ids_after_test)}) after selecting test set \"\n",
    "        f\"to satisfy {N_VALIDATION_MODELS} for validation. \"\n",
    "        f\"Consider reducing N_TEST_MODELS or N_VALIDATION_MODELS, or increasing total models.\"\n",
    "    )\n",
    "\n",
    "# Select validation model IDs from the remainder\n",
    "val_model_ids = remaining_ids_after_test[:N_VALIDATION_MODELS]\n",
    "\n",
    "# The rest go to training\n",
    "train_model_ids = remaining_ids_after_test[N_VALIDATION_MODELS:]\n",
    "\n",
    "if len(train_model_ids) == 0:\n",
    "    print(\"Warning: No models remaining for the training set after allocating to validation and test.\")\n",
    "\n",
    "\n",
    "print(f\"Number of models for Training: {len(train_model_ids)}\")\n",
    "print(f\"Number of models for Validation: {len(val_model_ids)}\")\n",
    "print(f\"Number of models for Testing: {len(test_model_ids)}\")\n",
    "\n",
    "# Create DataFrames based on the split model_ids\n",
    "train_df = combined_df[combined_df['model_id'].isin(train_model_ids)].copy()\n",
    "validation_df = combined_df[combined_df['model_id'].isin(val_model_ids)].copy()\n",
    "test_df = combined_df[combined_df['model_id'].isin(test_model_ids)].copy()\n",
    "\n",
    "print(f\"\\nShape of Training DataFrame: {train_df.shape}\")\n",
    "print(f\"Shape of Validation DataFrame: {validation_df.shape}\")\n",
    "print(f\"Shape of Test DataFrame: {test_df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "497bfd4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving datasets to: data_split\n",
      "\n",
      "Successfully created and saved train_dataset.csv, validation_dataset.csv, and test_dataset.csv.\n"
     ]
    }
   ],
   "source": [
    "# --- 3. Save Split DataFrames to CSV Files ---\n",
    "print(f\"\\nSaving datasets to: {OUTPUT_DATA_PATH}\")\n",
    "os.makedirs(OUTPUT_DATA_PATH, exist_ok=True)\n",
    "\n",
    "train_df.to_csv(OUTPUT_DATA_PATH / \"train_dataset.csv\", index=False)\n",
    "validation_df.to_csv(OUTPUT_DATA_PATH / \"validation_dataset.csv\", index=False)\n",
    "test_df.to_csv(OUTPUT_DATA_PATH / \"test_dataset.csv\", index=False)\n",
    "\n",
    "print(\"\\nSuccessfully created and saved train_dataset.csv, validation_dataset.csv, and test_dataset.csv.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4a38ca90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Verification of splits (first few model_ids in each set):\n",
      "Train model_ids sample: [11 14  8 13  2]\n",
      "Validation model_ids sample: [ 5 15]\n",
      "Test model_ids sample: [0 1]\n",
      "Overlap train-val: 0\n",
      "Overlap train-test: 0\n",
      "Overlap val-test: 0\n",
      "\n",
      "Example rows from train_dataset.csv:\n",
      "   threshold         flops  non_zero_params  params_reduction_pct  \\\n",
      "0        0.0  5.586813e+09         66955009              0.000000   \n",
      "1        0.1  5.427130e+09         65041295              2.858209   \n",
      "2        0.2  5.270893e+09         63168879              5.654737   \n",
      "3        0.3  5.121136e+09         61374123              8.335278   \n",
      "4        0.4  4.979191e+09         59672984             10.875997   \n",
      "\n",
      "   flops_reduction_pct  overall_accuracy  overall_f1  overall_precision  \\\n",
      "0             0.000000             0.988    0.987999           0.988125   \n",
      "1             2.858209             0.988    0.987999           0.988125   \n",
      "2             5.654737             0.988    0.987999           0.988125   \n",
      "3             8.335278             0.988    0.987999           0.988125   \n",
      "4            10.875997             0.988    0.987999           0.988125   \n",
      "\n",
      "   overall_recall  ham_accuracy    ham_f1  ham_precision  ham_recall  \\\n",
      "0           0.988         0.996  0.988095       0.980315       0.996   \n",
      "1           0.988         0.996  0.988095       0.980315       0.996   \n",
      "2           0.988         0.996  0.988095       0.980315       0.996   \n",
      "3           0.988         0.996  0.988095       0.980315       0.996   \n",
      "4           0.988         0.996  0.988095       0.980315       0.996   \n",
      "\n",
      "   spam_accuracy   spam_f1  spam_precision  spam_recall  model_id  \n",
      "0           0.98  0.987903        0.995935         0.98         2  \n",
      "1           0.98  0.987903        0.995935         0.98         2  \n",
      "2           0.98  0.987903        0.995935         0.98         2  \n",
      "3           0.98  0.987903        0.995935         0.98         2  \n",
      "4           0.98  0.987903        0.995935         0.98         2  \n"
     ]
    }
   ],
   "source": [
    "# --- Optional: Verification ---\n",
    "print(\"\\nVerification of splits (first few model_ids in each set):\")\n",
    "print(f\"Train model_ids sample: {train_model_ids[:5] if len(train_model_ids) > 0 else 'N/A'}\")\n",
    "print(f\"Validation model_ids sample: {val_model_ids[:5] if len(val_model_ids) > 0 else 'N/A'}\")\n",
    "print(f\"Test model_ids sample: {test_model_ids[:5] if len(test_model_ids) > 0 else 'N/A'}\")\n",
    "\n",
    "train_set = set(train_model_ids); val_set = set(val_model_ids); test_set = set(test_model_ids)\n",
    "print(f\"Overlap train-val: {len(train_set.intersection(val_set))}\")\n",
    "print(f\"Overlap train-test: {len(train_set.intersection(test_set))}\")\n",
    "print(f\"Overlap val-test: {len(val_set.intersection(test_set))}\")\n",
    "\n",
    "print(f\"\\nExample rows from train_dataset.csv:\")\n",
    "print(pd.read_csv(OUTPUT_DATA_PATH / \"train_dataset.csv\").head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "maai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
