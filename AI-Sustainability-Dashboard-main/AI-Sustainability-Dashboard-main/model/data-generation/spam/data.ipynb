{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31632599",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "from matplotlib.gridspec import GridSpec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "28b772e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading CSV files from model directories...\n",
      "Loaded data for model: WonderfulAnalytics_distilbert-base-uncased-finetuned-spam\n",
      "Loaded data for model: fzn0x_bert-spam-classification-model\n",
      "Loaded data for model: skandavivek2_spam-classifier\n",
      "Loaded data for model: SalehAhmad_roberta-base-finetuned-sms-spam-ham-detection\n",
      "Loaded data for model: sureshs_distilbert-large-sms-spam\n",
      "Loaded data for model: Ngadou_bert-sms-spam-dectector\n",
      "Loaded data for model: cesullivan99_sms-spam-weighted\n",
      "Loaded data for model: dungnt_sms_spam_detection\n",
      "Loaded data for model: mrm8488_bert-tiny-finetuned-enron-spam-detection\n",
      "Loaded data for model: nelsi_test_spam\n",
      "Loaded data for model: AntiSpamInstitute_spam-detector-bert-MoE-v2.2\n",
      "Loaded data for model: HJOK_task2_deberta_spamMLM_v1\n",
      "Loaded data for model: satish860_sms_spam_detection-manning\n",
      "Loaded data for model: wesleyacheng_sms-spam-classification-with-bert\n",
      "Loaded data for model: mshenoda_roberta-spam\n",
      "Loaded data for model: mrm8488_bert-tiny-finetuned-sms-spam-detection\n",
      "Loaded data for model: leeboykt_sms_spam_detection\n",
      "\n",
      "Original Data Summary:\n",
      "                                                    Model  Data Points  Min Threshold  Max Threshold  Min Accuracy  Max Accuracy Max Params Reduction Max FLOPS Reduction\n",
      "WonderfulAnalytics_distilbert-base-uncased-finetuned-spam          101            0.0           10.0         0.500         0.994               86.32%              86.32%\n",
      "                     fzn0x_bert-spam-classification-model          101            0.0           10.0         0.500         0.993               84.37%              84.37%\n",
      "                             skandavivek2_spam-classifier          101            0.0           10.0         0.500         0.990               86.34%              86.34%\n",
      " SalehAhmad_roberta-base-finetuned-sms-spam-ham-detection          101            0.0           10.0         0.495         0.928               50.37%              50.37%\n",
      "                        sureshs_distilbert-large-sms-spam          101            0.0           10.0         0.500         0.997               86.32%              86.32%\n",
      "                           Ngadou_bert-sms-spam-dectector          101            0.0           10.0         0.500         0.812               84.37%              84.37%\n",
      "                           cesullivan99_sms-spam-weighted          101            0.0           10.0         0.500         0.977               84.35%              84.35%\n",
      "                                dungnt_sms_spam_detection          101            0.0           10.0         0.500         0.916               90.67%              90.67%\n",
      "         mrm8488_bert-tiny-finetuned-enron-spam-detection          101            0.0           10.0         0.465         0.600               71.18%              71.18%\n",
      "                                          nelsi_test_spam          101            0.0           10.0         0.500         0.925               79.53%              79.53%\n",
      "            AntiSpamInstitute_spam-detector-bert-MoE-v2.2          101            0.0           10.0         0.730         0.994               71.21%              71.21%\n",
      "                            HJOK_task2_deberta_spamMLM_v1          101            0.0           10.0         0.406         0.567               75.32%              75.32%\n",
      "                     satish860_sms_spam_detection-manning          101            0.0           10.0         0.517         0.986               86.30%              86.30%\n",
      "           wesleyacheng_sms-spam-classification-with-bert          101            0.0           10.0         0.832         0.973               86.31%              86.31%\n",
      "                                    mshenoda_roberta-spam          101            0.0           10.0         0.498         0.996               74.48%              74.48%\n",
      "           mrm8488_bert-tiny-finetuned-sms-spam-detection          101            0.0           10.0         0.829         0.959               71.21%              71.21%\n",
      "                              leeboykt_sms_spam_detection          101            0.0           10.0         0.500         0.812               90.67%              90.67%\n",
      "\n",
      "Creating plots with original data...\n",
      "All comparative plots saved to 'comparison_plots' directory\n",
      "\n",
      "Analysis complete!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1400x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set plot style and colors\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "from matplotlib.gridspec import GridSpec\n",
    "from scipy.signal import savgol_filter\n",
    "\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_palette(\"Set2\")\n",
    "plt.rcParams['figure.figsize'] = [12, 8]\n",
    "plt.rcParams['figure.dpi'] = 100\n",
    "\n",
    "def smooth_data(data, method='savgol', window_size=5):\n",
    "    \"\"\"Apply smoothing to a data series using specified method\"\"\"\n",
    "    if len(data) < window_size:\n",
    "        return data  # Not enough data points to smooth\n",
    "        \n",
    "    if method == 'moving_avg':\n",
    "        # Simple moving average\n",
    "        return data.rolling(window=window_size, center=True).mean().fillna(data)\n",
    "    elif method == 'exponential':\n",
    "        # Exponential moving average\n",
    "        return data.ewm(span=window_size, adjust=True).mean()\n",
    "    elif method == 'savgol':\n",
    "        # Savitzky-Golay filter (good for maintaining peaks)\n",
    "        # For savgol_filter, window_length must be odd and > polyorder\n",
    "        if window_size % 2 == 0:\n",
    "            window_size += 1  # Ensure window size is odd\n",
    "        polyorder = min(2, window_size - 1)  # Ensure polyorder < window_length\n",
    "        return pd.Series(savgol_filter(data, window_length=window_size, polyorder=polyorder), index=data.index)\n",
    "    else:\n",
    "        return data\n",
    "\n",
    "def load_model_csvs(base_directory='runs', smooth=False, smooth_method='savgol', window_size=5):\n",
    "    \"\"\"Load CSV files with option to generate smoothed versions\"\"\"\n",
    "    # Dictionary to store dataframes by model\n",
    "    model_dfs = {}\n",
    "    model_dfs_smooth = {}  # For smoothed versions\n",
    "    \n",
    "    # Get all model directories\n",
    "    model_dirs = [d for d in os.listdir(base_directory) \n",
    "                 if os.path.isdir(os.path.join(base_directory, d))]\n",
    "    \n",
    "    # Process each model directory\n",
    "    for model_name in model_dirs:\n",
    "        # Path to the CSV file\n",
    "        csv_path = os.path.join(base_directory, model_name, 'pruning_results.csv')\n",
    "        \n",
    "        # Check if the CSV file exists\n",
    "        if os.path.exists(csv_path):\n",
    "            # Read the CSV\n",
    "            df = pd.read_csv(csv_path)\n",
    "\n",
    "            # Rename the overall_accuracy column to accuracy\n",
    "            if 'overall_accuracy' in df.columns:\n",
    "                df.rename(columns={'overall_accuracy': 'accuracy'}, inplace=True)\n",
    "            \n",
    "            # Add a column to identify the model\n",
    "            df['model'] = model_name\n",
    "            \n",
    "            # Store in dictionary\n",
    "            model_dfs[model_name] = df\n",
    "            \n",
    "            # Create smoothed version if requested\n",
    "            if smooth:\n",
    "                df_smooth = df.copy()\n",
    "                \n",
    "                # Apply smoothing to relevant metrics\n",
    "                metrics_to_smooth = ['accuracy', 'overall_f1', 'ham_accuracy', 'ham_f1', \n",
    "                                     'spam_accuracy', 'spam_f1']\n",
    "                \n",
    "                for metric in metrics_to_smooth:\n",
    "                    if metric in df_smooth.columns:\n",
    "                        # Sort by threshold before smoothing for better results\n",
    "                        df_sorted = df_smooth.sort_values('threshold')\n",
    "                        smoothed_values = smooth_data(df_sorted[metric], method=smooth_method, window_size=window_size)\n",
    "                        # Create new column with smooth_ prefix\n",
    "                        df_smooth[f'smooth_{metric}'] = smoothed_values.values\n",
    "                \n",
    "                # Store the smoothed dataframe\n",
    "                model_dfs_smooth[model_name] = df_smooth\n",
    "                \n",
    "                # Save smoothed version to CSV\n",
    "                smooth_dir = os.path.join(base_directory, model_name, 'smoothed')\n",
    "                os.makedirs(smooth_dir, exist_ok=True)\n",
    "                smooth_csv_path = os.path.join(smooth_dir, f'pruning_results_smooth_{smooth_method}_w{window_size}.csv')\n",
    "                df_smooth.to_csv(smooth_csv_path, index=False)\n",
    "                \n",
    "            print(f\"Loaded data for model: {model_name}\")\n",
    "        else:\n",
    "            print(f\"Warning: No CSV file found for model {model_name} at {csv_path}\")\n",
    "    \n",
    "    # Combine all for overall analysis\n",
    "    if model_dfs:\n",
    "        all_data = pd.concat(list(model_dfs.values()), ignore_index=True)\n",
    "        if smooth:\n",
    "            all_data_smooth = pd.concat(list(model_dfs_smooth.values()), ignore_index=True)\n",
    "            return model_dfs, all_data, model_dfs_smooth, all_data_smooth\n",
    "        return model_dfs, all_data\n",
    "    else:\n",
    "        print(\"No CSV files were found. Check your directory structure.\")\n",
    "        if smooth:\n",
    "            return {}, pd.DataFrame(), {}, pd.DataFrame()\n",
    "        return {}, pd.DataFrame()\n",
    "\n",
    "def create_comparative_plots(model_dfs, all_data, output_dir='comparison_plots', \n",
    "                            use_smoothed=False, model_dfs_smooth=None, all_data_smooth=None, \n",
    "                            smooth_method='savgol', window_size=5):\n",
    "    \"\"\"Create comparative plots to visualize model behaviors with optional smoothed data\"\"\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Determine if we need to add smoothed suffix to output files\n",
    "    smooth_suffix = f\"_smooth_{smooth_method}_w{window_size}\" if use_smoothed else \"\"\n",
    "    \n",
    "    # Choose which dataframes to use based on smoothed preference\n",
    "    if use_smoothed and model_dfs_smooth:\n",
    "        plot_dfs = model_dfs_smooth\n",
    "        accuracy_col = 'smooth_accuracy'  # Use smoothed version\n",
    "    else:\n",
    "        plot_dfs = model_dfs\n",
    "        accuracy_col = 'accuracy'  # Use original version\n",
    "    \n",
    "    # Get list of models\n",
    "    models = list(plot_dfs.keys())\n",
    "    \n",
    "    # Define colors for consistent plotting - expanded for 17 models\n",
    "    colors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd', \n",
    "              '#8c564b', '#e377c2', '#7f7f7f', '#bcbd22', '#17becf',\n",
    "              '#aec7e8', '#ffbb78', '#98df8a', '#ff9896', '#c5b0d5',\n",
    "              '#c49c94', '#f7b6d3']\n",
    "    \n",
    "    # 1. PLOT: FLOPS and Parameters Reduction by Model\n",
    "    plt.figure(figsize=(14, 10))\n",
    "    \n",
    "    # Create a summary DataFrame\n",
    "    reduction_summary = []\n",
    "    for model, df in plot_dfs.items():\n",
    "        # For each model, get the min/max threshold data points\n",
    "        min_threshold_row = df.loc[df['threshold'].idxmin()]\n",
    "        max_threshold_row = df.loc[df['threshold'].idxmax()]\n",
    "        \n",
    "        reduction_summary.append({\n",
    "            'Model': model,\n",
    "            'Initial Params Reduction (%)': min_threshold_row['params_reduction_pct'],\n",
    "            'Final Params Reduction (%)': max_threshold_row['params_reduction_pct'],\n",
    "            'Initial FLOPS Reduction (%)': min_threshold_row['flops_reduction_pct'],\n",
    "            'Final FLOPS Reduction (%)': max_threshold_row['flops_reduction_pct'],\n",
    "            'Initial Accuracy': min_threshold_row[accuracy_col],\n",
    "            'Final Accuracy': max_threshold_row[accuracy_col],\n",
    "            'Accuracy Change': max_threshold_row[accuracy_col] - min_threshold_row[accuracy_col]\n",
    "        })\n",
    "    \n",
    "    red_df = pd.DataFrame(reduction_summary)\n",
    "    \n",
    "    # Sort by final params reduction\n",
    "    red_df = red_df.sort_values('Final Params Reduction (%)', ascending=False)\n",
    "    \n",
    "    # Create subplot grid\n",
    "    fig = plt.figure(figsize=(18, 12))\n",
    "    gs = GridSpec(2, 2, figure=fig, height_ratios=[1, 1])\n",
    "    \n",
    "    # 1. Params Reduction Plot\n",
    "    ax1 = fig.add_subplot(gs[0, 0])\n",
    "    \n",
    "    for i, model in enumerate(red_df['Model']):\n",
    "        ax1.plot([0, 1], \n",
    "                [red_df.loc[red_df['Model']==model, 'Initial Params Reduction (%)'].values[0],\n",
    "                 red_df.loc[red_df['Model']==model, 'Final Params Reduction (%)'].values[0]],\n",
    "                'o-', linewidth=2, label=model, color=colors[i % len(colors)])\n",
    "    \n",
    "    ax1.set_xlim(-0.1, 1.1)\n",
    "    ax1.set_xticks([0, 1])\n",
    "    ax1.set_xticklabels(['Initial', 'Final'])\n",
    "    ax1.set_ylabel('Parameters Reduction (%)')\n",
    "    ax1.set_title('Parameters Reduction: Initial vs Final')\n",
    "    ax1.grid(True, linestyle='--', alpha=0.7)\n",
    "    \n",
    "    # 2. FLOPS Reduction Plot\n",
    "    ax2 = fig.add_subplot(gs[0, 1])\n",
    "    \n",
    "    for i, model in enumerate(red_df['Model']):\n",
    "        ax2.plot([0, 1], \n",
    "                [red_df.loc[red_df['Model']==model, 'Initial FLOPS Reduction (%)'].values[0],\n",
    "                 red_df.loc[red_df['Model']==model, 'Final FLOPS Reduction (%)'].values[0]],\n",
    "                'o-', linewidth=2, label=model, color=colors[i % len(colors)])\n",
    "    \n",
    "    ax2.set_xlim(-0.1, 1.1)\n",
    "    ax2.set_xticks([0, 1])\n",
    "    ax2.set_xticklabels(['Initial', 'Final'])\n",
    "    ax2.set_ylabel('FLOPS Reduction (%)')\n",
    "    ax2.set_title('FLOPS Reduction: Initial vs Final')\n",
    "    ax2.grid(True, linestyle='--', alpha=0.7)\n",
    "    \n",
    "    # 3. Accuracy Change Plot\n",
    "    ax3 = fig.add_subplot(gs[1, 0])\n",
    "    \n",
    "    for i, model in enumerate(red_df['Model']):\n",
    "        ax3.plot([0, 1], \n",
    "                [red_df.loc[red_df['Model']==model, 'Initial Accuracy'].values[0],\n",
    "                 red_df.loc[red_df['Model']==model, 'Final Accuracy'].values[0]],\n",
    "                'o-', linewidth=2, label=model, color=colors[i % len(colors)])\n",
    "    \n",
    "    ax3.set_xlim(-0.1, 1.1)\n",
    "    ax3.set_xticks([0, 1])\n",
    "    ax3.set_xticklabels(['Initial', 'Final'])\n",
    "    ax3.set_ylabel('Accuracy')\n",
    "    ax3.set_title('Accuracy: Initial vs Final')\n",
    "    ax3.grid(True, linestyle='--', alpha=0.7)\n",
    "    \n",
    "    # 4. Tradeoff: Accuracy Change vs Params Reduction\n",
    "    ax4 = fig.add_subplot(gs[1, 1])\n",
    "    \n",
    "    scatter = ax4.scatter(\n",
    "        red_df['Final Params Reduction (%)'] - red_df['Initial Params Reduction (%)'],\n",
    "        red_df['Accuracy Change'],\n",
    "        s=100, c=np.arange(len(red_df)), cmap='viridis', alpha=0.8\n",
    "    )\n",
    "    \n",
    "    # Add model names as annotations\n",
    "    for i, row in red_df.iterrows():\n",
    "        ax4.annotate(row['Model'], \n",
    "                   (row['Final Params Reduction (%)'] - row['Initial Params Reduction (%)'], \n",
    "                    row['Accuracy Change']),\n",
    "                   xytext=(5, 5), textcoords='offset points')\n",
    "    \n",
    "    ax4.axhline(y=0, color='r', linestyle='--', alpha=0.5)\n",
    "    ax4.set_xlabel('Params Reduction Change (%)')\n",
    "    ax4.set_ylabel('Accuracy Change')\n",
    "    ax4.set_title('Tradeoff: Accuracy Change vs Params Reduction Change')\n",
    "    ax4.grid(True, linestyle='--', alpha=0.7)\n",
    "    \n",
    "    # Add a single legend for all subplots - FIXED POSITIONING\n",
    "    handles, labels = ax1.get_legend_handles_labels()\n",
    "    fig.legend(handles, labels, loc='center left', bbox_to_anchor=(1.02, 0.5), \n",
    "               ncol=1, frameon=True, fontsize=9)\n",
    "    \n",
    "    # Add smoothed title if applicable\n",
    "    smooth_title = f\" (Smoothed: {smooth_method}, window={window_size})\" if use_smoothed else \"\"\n",
    "    fig.suptitle(f\"Reduction Comparison{smooth_title}\", fontsize=16, y=0.98)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.subplots_adjust(right=0.75)  # Make room for legend on the right\n",
    "    plt.savefig(f\"{output_dir}/reduction_comparison_grid{smooth_suffix}.png\", bbox_inches='tight', dpi=150)\n",
    "    plt.close()\n",
    "    \n",
    "    # 3. PLOT: Threshold vs. Accuracy for all models - FIXED LEGEND\n",
    "    plt.figure(figsize=(16, 10))\n",
    "    \n",
    "    for i, (model, df) in enumerate(plot_dfs.items()):\n",
    "        # Sort by threshold for a smooth line\n",
    "        df_sorted = df.sort_values('threshold')\n",
    "        plt.plot(df_sorted['threshold'], df_sorted[accuracy_col], 'o-', \n",
    "                linewidth=2, label=model, color=colors[i % len(colors)])\n",
    "    \n",
    "    # Improve x-axis readability\n",
    "    max_threshold = max([df['threshold'].max() for df in plot_dfs.values()])\n",
    "    x_ticks = np.arange(0, max_threshold + 0.5, 0.5)\n",
    "    plt.xticks(x_ticks)\n",
    "    \n",
    "    plt.xlabel('Threshold')\n",
    "    plt.ylabel('Accuracy')\n",
    "    title = f'Threshold vs Accuracy (All models){smooth_title}'\n",
    "    plt.title(title)\n",
    "    plt.grid(True, linestyle='--', alpha=0.7)\n",
    "    \n",
    "    # FIXED LEGEND POSITIONING - Use plt.legend instead of fig.legend\n",
    "    plt.legend(loc='center left', bbox_to_anchor=(1.02, 0.5), \n",
    "               frameon=True, fontsize=9)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.subplots_adjust(right=0.75)  # Make room for legend\n",
    "    plt.savefig(f\"{output_dir}/threshold_vs_accuracy_all_models{smooth_suffix}.png\", \n",
    "                bbox_inches='tight', dpi=150)\n",
    "    plt.close()\n",
    "    \n",
    "    # 4. PLOT: Efficiency Frontier (Params Reduction vs Accuracy) - FIXED LEGEND\n",
    "    plt.figure(figsize=(16, 10))\n",
    "    \n",
    "    for i, (model, df) in enumerate(plot_dfs.items()):\n",
    "        plt.plot(df['params_reduction_pct'], df[accuracy_col], 'o-', \n",
    "                linewidth=2, label=model, color=colors[i % len(colors)])\n",
    "    \n",
    "    plt.xlabel('Parameters Reduction (%)')\n",
    "    plt.ylabel('Accuracy')\n",
    "    title = f'Efficiency Frontier: Params Reduction vs Accuracy{smooth_title}'\n",
    "    plt.title(title)\n",
    "    plt.grid(True, linestyle='--', alpha=0.7)\n",
    "    \n",
    "    # FIXED LEGEND POSITIONING\n",
    "    plt.legend(loc='center left', bbox_to_anchor=(1.02, 0.5), \n",
    "               frameon=True, fontsize=9)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.subplots_adjust(right=0.75)\n",
    "    plt.savefig(f\"{output_dir}/params_reduction_vs_accuracy_all_models{smooth_suffix}.png\", \n",
    "                bbox_inches='tight', dpi=150)\n",
    "    plt.close()\n",
    "    \n",
    "    # 5. PLOT: FLOPS Reduction vs Accuracy - FIXED LEGEND\n",
    "    plt.figure(figsize=(16, 10))\n",
    "    \n",
    "    for i, (model, df) in enumerate(plot_dfs.items()):\n",
    "        plt.plot(df['flops_reduction_pct'], df[accuracy_col], 'o-', \n",
    "                linewidth=2, label=model, color=colors[i % len(colors)])\n",
    "    \n",
    "    plt.xlabel('FLOPS Reduction (%)')\n",
    "    plt.ylabel('Accuracy')\n",
    "    title = f'Efficiency Frontier: FLOPS Reduction vs Accuracy{smooth_title}'\n",
    "    plt.title(title)\n",
    "    plt.grid(True, linestyle='--', alpha=0.7)\n",
    "    \n",
    "    # FIXED LEGEND POSITIONING\n",
    "    plt.legend(loc='center left', bbox_to_anchor=(1.02, 0.5), \n",
    "               frameon=True, fontsize=9)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.subplots_adjust(right=0.75)\n",
    "    plt.savefig(f\"{output_dir}/flops_reduction_vs_accuracy_all_models{smooth_suffix}.png\", \n",
    "                bbox_inches='tight', dpi=150)\n",
    "    plt.close()\n",
    "    \n",
    "    # 6. PLOT: Direct Model Comparison Table (as image)\n",
    "    # Create a summary table for quick comparison\n",
    "    summary_data = []\n",
    "    for model, df in plot_dfs.items():\n",
    "        min_threshold_row = df.loc[df['threshold'].idxmin()]\n",
    "        max_threshold_row = df.loc[df['threshold'].idxmax()]\n",
    "        best_acc_row = df.loc[df[accuracy_col].idxmax()]\n",
    "        \n",
    "        summary_data.append({\n",
    "            'Model': model,\n",
    "            'Best Acc.': f\"{df[accuracy_col].max():.4f}\",\n",
    "            'At Thresh.': f\"{best_acc_row['threshold']:.3f}\",\n",
    "            'Final Acc.': f\"{max_threshold_row[accuracy_col]:.4f}\",\n",
    "            'Acc. Drop': f\"{df[accuracy_col].max() - max_threshold_row[accuracy_col]:.4f}\",\n",
    "            'Params Red.': f\"{max_threshold_row['params_reduction_pct']:.1f}%\",\n",
    "            'FLOPS Red.': f\"{max_threshold_row['flops_reduction_pct']:.1f}%\",\n",
    "        })\n",
    "    \n",
    "    # Convert to DataFrame and sort by best accuracy\n",
    "    summary_df = pd.DataFrame(summary_data)\n",
    "    summary_df = summary_df.sort_values('Best Acc.', ascending=False)\n",
    "    \n",
    "    # Create figure and axis\n",
    "    fig, ax = plt.subplots(figsize=(12, 2 + 0.5*len(plot_dfs)))\n",
    "    \n",
    "    # Turn off axis\n",
    "    ax.axis('off')\n",
    "    ax.axis('tight')\n",
    "    \n",
    "    # Create table\n",
    "    table = ax.table(cellText=summary_df.values, colLabels=summary_df.columns, \n",
    "                    loc='center', cellLoc='center')\n",
    "    \n",
    "    # Style the table\n",
    "    table.auto_set_font_size(False)\n",
    "    table.set_fontsize(10)\n",
    "    table.scale(1.2, 1.5)\n",
    "    \n",
    "    # Color the header row\n",
    "    for j in range(len(summary_df.columns)):\n",
    "        table[(0, j)].set_facecolor('#4472C4')\n",
    "        table[(0, j)].set_text_props(color='white', fontweight='bold')\n",
    "    \n",
    "    title = f'Model Performance Summary{smooth_title}'\n",
    "    plt.title(title, pad=20, fontsize=14)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"{output_dir}/model_summary_table{smooth_suffix}.png\", bbox_inches='tight', dpi=150)\n",
    "    plt.close()\n",
    "    \n",
    "    # If we have both original and smoothed data, create comparison plots\n",
    "    if use_smoothed and 'model_dfs' in locals():\n",
    "        # Create original vs smoothed accuracy comparison\n",
    "        plt.figure(figsize=(16, 10))\n",
    "        \n",
    "        for i, model in enumerate(models):\n",
    "            if model in model_dfs and model in model_dfs_smooth:\n",
    "                df_orig = model_dfs[model].sort_values('threshold')\n",
    "                df_smooth = model_dfs_smooth[model].sort_values('threshold')\n",
    "                \n",
    "                # Plot original data with transparency\n",
    "                plt.plot(df_orig['threshold'], df_orig['accuracy'], \n",
    "                         '--', alpha=0.3, linewidth=1, label=f\"{model} (Original)\",\n",
    "                         color=colors[i % len(colors)])\n",
    "                \n",
    "                # Plot smoothed data with solid line\n",
    "                plt.plot(df_smooth['threshold'], df_smooth['smooth_accuracy'], \n",
    "                         '-', linewidth=2, label=f\"{model} (Smoothed)\",\n",
    "                         color=colors[i % len(colors)])\n",
    "        \n",
    "        # Improve x-axis readability\n",
    "        max_threshold = max([df['threshold'].max() for df in plot_dfs.values()])\n",
    "        x_ticks = np.arange(0, max_threshold + 0.5, 0.5)\n",
    "        plt.xticks(x_ticks)\n",
    "        \n",
    "        plt.xlabel('Threshold')\n",
    "        plt.ylabel('Accuracy')\n",
    "        plt.title(f'Original vs. Smoothed Accuracy ({smooth_method}, window={window_size})')\n",
    "        plt.grid(True, linestyle='--', alpha=0.7)\n",
    "        \n",
    "        # FIXED LEGEND POSITIONING\n",
    "        plt.legend(loc='center left', bbox_to_anchor=(1.02, 0.5), \n",
    "                   frameon=True, fontsize=8)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.subplots_adjust(right=0.75)\n",
    "        plt.savefig(f\"{output_dir}/original_vs_smoothed_accuracy.png\", bbox_inches='tight', dpi=150)\n",
    "        plt.close()\n",
    "\n",
    "    print(f\"All comparative plots saved to '{output_dir}' directory\")\n",
    "\n",
    "def run_comparison_analysis(base_directory='datasets', smooth=True, smooth_method='savgol', window_size=5):\n",
    "    \"\"\"Run the comparative analysis with option for smoothed data\"\"\"\n",
    "    print(\"Loading CSV files from model directories...\")\n",
    "    \n",
    "    if smooth:\n",
    "        model_dfs, all_data, model_dfs_smooth, all_data_smooth = load_model_csvs(\n",
    "            base_directory, smooth=True, smooth_method=smooth_method, window_size=window_size)\n",
    "    else:\n",
    "        model_dfs, all_data = load_model_csvs(base_directory)\n",
    "    \n",
    "    if not model_dfs:\n",
    "        print(\"No data to analyze. Exiting.\")\n",
    "        return\n",
    "    \n",
    "    # Create summary table for original data\n",
    "    model_summary = []\n",
    "    for model, df in model_dfs.items():\n",
    "        model_summary.append({\n",
    "            'Model': model,\n",
    "            'Data Points': len(df),\n",
    "            'Min Threshold': df['threshold'].min(),\n",
    "            'Max Threshold': df['threshold'].max(),\n",
    "            'Min Accuracy': df['accuracy'].min(),\n",
    "            'Max Accuracy': df['accuracy'].max(),\n",
    "            'Max Params Reduction': f\"{df['params_reduction_pct'].max():.2f}%\",\n",
    "            'Max FLOPS Reduction': f\"{df['flops_reduction_pct'].max():.2f}%\"\n",
    "        })\n",
    "    \n",
    "    # Print summary\n",
    "    print(\"\\nOriginal Data Summary:\")\n",
    "    summary_df = pd.DataFrame(model_summary)\n",
    "    print(summary_df.to_string(index=False))\n",
    "    \n",
    "    print(\"\\nCreating plots with original data...\")\n",
    "    create_comparative_plots(model_dfs, all_data)\n",
    "    \n",
    "    # If smoothing is enabled, create smoothed plots\n",
    "    if smooth and model_dfs_smooth:\n",
    "        print(f\"\\nCreating plots with smoothed data ({smooth_method}, window={window_size})...\")\n",
    "        \n",
    "        # Create summary table for smoothed data\n",
    "        smooth_summary = []\n",
    "        for model, df in model_dfs_smooth.items():\n",
    "            smooth_summary.append({\n",
    "                'Model': model,\n",
    "                'Data Points': len(df),\n",
    "                'Min Threshold': df['threshold'].min(),\n",
    "                'Max Threshold': df['threshold'].max(),\n",
    "                'Min Smooth Acc': df['smooth_accuracy'].min(),\n",
    "                'Max Smooth Acc': df['smooth_accuracy'].max(),\n",
    "                'Max Params Reduction': f\"{df['params_reduction_pct'].max():.2f}%\",\n",
    "                'Max FLOPS Reduction': f\"{df['flops_reduction_pct'].max():.2f}%\"\n",
    "            })\n",
    "        \n",
    "        # Print smoothed summary\n",
    "        print(\"\\nSmoothed Data Summary:\")\n",
    "        smooth_df = pd.DataFrame(smooth_summary)\n",
    "        print(smooth_df.to_string(index=False))\n",
    "        \n",
    "        # Create smoothed plots\n",
    "        smooth_dir = f\"comparison_plots_smooth_{smooth_method}_w{window_size}\"\n",
    "        create_comparative_plots(model_dfs, all_data, \n",
    "                                output_dir=smooth_dir,\n",
    "                                use_smoothed=True, \n",
    "                                model_dfs_smooth=model_dfs_smooth, \n",
    "                                all_data_smooth=all_data_smooth,\n",
    "                                smooth_method=smooth_method,\n",
    "                                window_size=window_size)\n",
    "        \n",
    "        # Also create original vs smoothed comparison plots\n",
    "        print(\"\\nCreating original vs smoothed comparison plots...\")\n",
    "        comparison_dir = \"comparison_plots_orig_vs_smooth\"\n",
    "        os.makedirs(comparison_dir, exist_ok=True)\n",
    "        \n",
    "        # For each model, create original vs smoothed plots\n",
    "        for i, model in enumerate(model_dfs.keys()):\n",
    "            if model in model_dfs_smooth:\n",
    "                plt.figure(figsize=(16, 8))\n",
    "                \n",
    "                df_orig = model_dfs[model].sort_values('threshold')\n",
    "                df_smooth = model_dfs_smooth[model].sort_values('threshold')\n",
    "                \n",
    "                # Plot original data\n",
    "                plt.plot(df_orig['threshold'], df_orig['accuracy'], \n",
    "                         'o--', alpha=0.5, label='Original')\n",
    "                \n",
    "                # Plot smoothed data\n",
    "                plt.plot(df_smooth['threshold'], df_smooth['smooth_accuracy'], \n",
    "                         '-', linewidth=2.5, label=f'Smoothed ({smooth_method}, window={window_size})')\n",
    "                \n",
    "                # Improve x-axis readability\n",
    "                max_threshold = df_orig['threshold'].max()\n",
    "                x_ticks = np.arange(0, max_threshold + 0.5, 0.5)\n",
    "                plt.xticks(x_ticks)\n",
    "                \n",
    "                plt.xlabel('Threshold')\n",
    "                plt.ylabel('Accuracy')\n",
    "                plt.title(f'Original vs. Smoothed Accuracy: {model}')\n",
    "                plt.grid(True, linestyle='--', alpha=0.7)\n",
    "                plt.legend()\n",
    "                plt.tight_layout()\n",
    "                plt.savefig(f\"{comparison_dir}/{model}_original_vs_smooth.png\", bbox_inches='tight', dpi=150)\n",
    "                plt.close()\n",
    "    \n",
    "    print(\"\\nAnalysis complete!\")\n",
    "\n",
    "# Run the analysis with smoothing\n",
    "if __name__ == \"__main__\":\n",
    "    # Configure smoothing parameters\n",
    "    SMOOTH_METHOD = 'moving_avg'  # Options: 'moving_avg', 'exponential', 'savgol'\n",
    "    WINDOW_SIZE = 0  # Adjust based on how much smoothing you want\n",
    "    \n",
    "    run_comparison_analysis('runs', smooth=False, smooth_method=SMOOTH_METHOD, window_size=WINDOW_SIZE)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "maai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
