{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "import os\n",
    "import logging\n",
    "import time\n",
    "import gc\n",
    "import math\n",
    "import json \n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.inspection import permutation_importance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasetPath = 'flask_ml/data/Income_dataset.csv'  \n",
    "outputExcelFile = 'budget_gridsearch_fairness_results.xlsx'\n",
    "targetColumn = 'Income' \n",
    "protectedAttributesOriginal = ['age', 'race', 'sex']\n",
    "\n",
    "# Age binning as the dashboard does as well\n",
    "ageColumn = 'age'\n",
    "binnedAgeColumnName = 'age_bin'\n",
    "defaultAgeBins = [0, 24, 34, 44, 54, 64, np.inf]\n",
    "defaultAgeLabels = ['<25', '25-34', '35-44', '45-54', '55-64', '65+']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "testSize = 0.20\n",
    "randomState = 42\n",
    "lrParams = {'C': 1.0, 'solver': 'lbfgs', 'max_iter': 1000, 'random_state': randomState, 'class_weight': 'balanced'} \n",
    "maxBudgetFeatures = 9\n",
    "minBudgetFeatures = 1\n",
    "piNRepeats = 5 \n",
    "piNJobs = 1    \n",
    "minSamplesForPI = 15 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "fairnessMetricsSubgroup = ['Demographic Parity', 'Equalized Odds', 'FPR', 'Predictive Parity', 'Group Size']\n",
    "metricsForOverallDisparity = ['Demographic Parity', 'Equalized Odds', 'Predictive Parity'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logProgressEveryN = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_fairness_metrics(dfGroup):\n",
    "    \"\"\"Calculates fairness metrics for a given subgroup DataFrame.\"\"\"\n",
    "    if dfGroup.empty:\n",
    "        return {'Demographic Parity': np.nan, 'Equalized Odds': np.nan, 'FPR': np.nan, 'Predictive Parity': np.nan, 'Group Size': 0}\n",
    "\n",
    "    yTrue = dfGroup['y_true'].astype(int)\n",
    "    yPred = dfGroup['y_pred'].astype(int)\n",
    "    \n",
    "    tp = ((yTrue == 1) & (yPred == 1)).sum()\n",
    "    fp = ((yTrue == 0) & (yPred == 1)).sum()\n",
    "    tn = ((yTrue == 0) & (yPred == 0)).sum()\n",
    "    fn = ((yTrue == 1) & (yPred == 0)).sum()\n",
    "\n",
    "    predictedPositive = tp + fp\n",
    "    actualPositive = tp + fn\n",
    "    actualNegative = tn + fp\n",
    "    totalGroup = tp + fp + tn + fp \n",
    "\n",
    "    dpRate = predictedPositive / totalGroup if totalGroup > 0 else np.nan\n",
    "    tprRate = tp / actualPositive if actualPositive > 0 else np.nan \n",
    "    fprRate = fp / actualNegative if actualNegative > 0 else np.nan\n",
    "    ppRate = tp / predictedPositive if predictedPositive > 0 else np.nan\n",
    "\n",
    "    return {'Demographic Parity': dpRate,\n",
    "            'Equalized Odds': tprRate, \n",
    "            'FPR': fprRate,           \n",
    "            'Predictive Parity': ppRate,\n",
    "            'Group Size': totalGroup}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_age_binning(df, ageCol, binnedColName, bins, labels):\n",
    "    \"\"\"Applies binning to the specified age column.\"\"\"\n",
    "    dfBinned = df.copy()\n",
    "    if ageCol in dfBinned.columns and pd.api.types.is_numeric_dtype(dfBinned[ageCol]):\n",
    "        logging.info(f\"Attempting to bin numeric column '{ageCol}' into '{binnedColName}'.\")\n",
    "        try:\n",
    "             dfBinned[binnedColName] = pd.cut(dfBinned[ageCol], bins=bins, labels=labels, right=False, include_lowest=True)\n",
    "             dfBinned[binnedColName] = dfBinned[binnedColName].astype(str).fillna('NaN_Age_Bin')\n",
    "             logging.info(f\"Successfully binned '{ageCol}' into '{binnedColName}'. Unique values: {dfBinned[binnedColName].unique()}\")\n",
    "        except Exception as binErr:\n",
    "             logging.error(f\"Error binning age column '{ageCol}': {binErr}\", exc_info=True)\n",
    "             raise ValueError(f\"Failed to bin age column '{ageCol}'. Cannot proceed.\") from binErr\n",
    "    elif ageCol in dfBinned.columns:\n",
    "         logging.warning(f\"Column '{ageCol}' exists but is not numeric. Skipping binning.\")\n",
    "         dfBinned[binnedColName] = dfBinned[ageCol].astype(str).fillna('NaN_Age_Str')\n",
    "         logging.info(f\"Converted non-numeric '{ageCol}' to string as '{binnedColName}'.\")\n",
    "    else:\n",
    "        logging.error(f\"Age column '{ageCol}' not found in DataFrame. Cannot perform binning.\")\n",
    "        raise ValueError(f\"Required age column '{ageCol}' not found.\")\n",
    "\n",
    "    return dfBinned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-02 14:16:11,009 - INFO - --- Starting Data Loading and Preparation ---\n",
      "2025-05-02 14:16:11,071 - INFO - Successfully loaded dataset: flask_ml/data/Income_dataset.csv. Shape: (48842, 14)\n",
      "2025-05-02 14:16:11,194 - WARNING - Target values binary but not 0/1 (['<=50K' '>50K']). Mapping '<=50K'->0, '>50K'->1.\n",
      "2025-05-02 14:16:11,213 - INFO - Attempting to bin numeric column 'age' into 'age_bin'.\n",
      "2025-05-02 14:16:11,225 - INFO - Successfully binned 'age' into 'age_bin'. Unique values: ['35-44' '45-54' '25-34' '<25' '55-64' '65+']\n",
      "2025-05-02 14:16:11,225 - INFO - Protected attributes for analysis: ['age_bin', 'race', 'sex']\n",
      "2025-05-02 14:16:11,226 - INFO - Identified 10 potential features for model.\n",
      "2025-05-02 14:16:11,253 - INFO - Final dataset shape before split: (48842, 15)\n",
      "2025-05-02 14:16:11,303 - INFO - Data split complete: Train=39073, Test=9769\n",
      "2025-05-02 14:16:11,304 - INFO - --- Test Set Distribution for age_bin ---\n",
      "2025-05-02 14:16:11,306 - INFO - -----------------------------------------\n",
      "2025-05-02 14:16:11,366 - INFO - --- Preprocessing Data and Training Global Model ---\n",
      "2025-05-02 14:16:11,373 - INFO - Fitting global preprocessor...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age_bin\n",
      "25-34    2494\n",
      "35-44    2439\n",
      "45-54    1845\n",
      "<25      1474\n",
      "55-64    1041\n",
      "65+       476\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-02 14:16:11,526 - INFO - Preprocessing complete. Processed training features shape: (39073, 96)\n",
      "2025-05-02 14:16:11,526 - INFO - Training global Logistic Regression model...\n",
      "2025-05-02 14:16:11,825 - INFO - Global model training complete.\n",
      "2025-05-02 14:16:11,826 - INFO - --- Calculating Permutation Importance per Subgroup ---\n",
      "2025-05-02 14:16:11,827 - INFO - Calculating PI for subgroups in: age_bin\n",
      "2025-05-02 14:16:11,831 - INFO - Found groups in training data for age_bin: ['35-44' '55-64' '45-54' '65+' '25-34' '<25']\n",
      "2025-05-02 14:16:25,233 - INFO - Calculating PI for subgroups in: race\n",
      "2025-05-02 14:16:25,235 - INFO - Found groups in training data for race: ['White' 'Asian-Pac-Islander' 'Black' 'Other' 'Amer-Indian-Eskimo']\n",
      "2025-05-02 14:16:37,426 - INFO - Calculating PI for subgroups in: sex\n",
      "2025-05-02 14:16:37,429 - INFO - Found groups in training data for sex: ['Female' 'Male']\n",
      "2025-05-02 14:16:47,837 - INFO - --- Permutation Importance Calculation Finished. Duration: 36.01 sec ---\n",
      "2025-05-02 14:16:47,892 - INFO - --- Starting Budgeting Simulation Loop ---\n",
      "2025-05-02 14:16:47,892 - INFO - Preprocessing test data...\n",
      "2025-05-02 14:16:47,924 - INFO - Test data preprocessed. Shape: (9769, 96)\n",
      "2025-05-02 14:16:47,927 - INFO - --- Processing Budget Level N = 9 ---\n",
      "2025-05-02 14:16:59,024 - INFO - Budget N=9 -> Accuracy: 0.7995\n",
      "2025-05-02 14:16:59,088 - INFO - DEBUG: N=9, Group=25-34: Size=2494\n",
      "2025-05-02 14:16:59,089 - INFO -   y_true counts: {0: 2141, 1: 353}\n",
      "2025-05-02 14:16:59,089 - INFO -   y_pred counts: {0: 1740, 1: 754}\n",
      "2025-05-02 14:16:59,090 - INFO -   ActualPos=353, ActualNeg=2141, PredictedPos=754\n",
      "2025-05-02 14:16:59,093 - INFO - DEBUG: N=9, Group=55-64: Size=1041\n",
      "2025-05-02 14:16:59,094 - INFO -   y_true counts: {0: 707, 1: 334}\n",
      "2025-05-02 14:16:59,095 - INFO -   y_pred counts: {0: 634, 1: 407}\n",
      "2025-05-02 14:16:59,095 - INFO -   ActualPos=334, ActualNeg=707, PredictedPos=407\n",
      "2025-05-02 14:16:59,100 - INFO - DEBUG: N=9, Group=35-44: Size=2439\n",
      "2025-05-02 14:16:59,101 - INFO -   y_true counts: {0: 1637, 1: 802}\n",
      "2025-05-02 14:16:59,102 - INFO -   y_pred counts: {0: 1510, 1: 929}\n",
      "2025-05-02 14:16:59,103 - INFO -   ActualPos=802, ActualNeg=1637, PredictedPos=929\n",
      "2025-05-02 14:16:59,106 - INFO - DEBUG: N=9, Group=45-54: Size=1845\n",
      "2025-05-02 14:16:59,107 - INFO -   y_true counts: {0: 1124, 1: 721}\n",
      "2025-05-02 14:16:59,107 - INFO -   y_pred counts: {0: 1058, 1: 787}\n",
      "2025-05-02 14:16:59,108 - INFO -   ActualPos=721, ActualNeg=1124, PredictedPos=787\n",
      "2025-05-02 14:16:59,128 - INFO - --- Finished Budget N=9. Duration: 11.20 sec ---\n",
      "2025-05-02 14:16:59,181 - INFO - --- Processing Budget Level N = 8 ---\n",
      "2025-05-02 14:17:10,770 - INFO - Budget N=8 -> Accuracy: 0.7995\n",
      "2025-05-02 14:17:10,833 - INFO - DEBUG: N=8, Group=25-34: Size=2494\n",
      "2025-05-02 14:17:10,834 - INFO -   y_true counts: {0: 2141, 1: 353}\n",
      "2025-05-02 14:17:10,834 - INFO -   y_pred counts: {0: 1779, 1: 715}\n",
      "2025-05-02 14:17:10,835 - INFO -   ActualPos=353, ActualNeg=2141, PredictedPos=715\n",
      "2025-05-02 14:17:10,838 - INFO - DEBUG: N=8, Group=55-64: Size=1041\n",
      "2025-05-02 14:17:10,839 - INFO -   y_true counts: {0: 707, 1: 334}\n",
      "2025-05-02 14:17:10,839 - INFO -   y_pred counts: {0: 637, 1: 404}\n",
      "2025-05-02 14:17:10,840 - INFO -   ActualPos=334, ActualNeg=707, PredictedPos=404\n",
      "2025-05-02 14:17:10,846 - INFO - DEBUG: N=8, Group=35-44: Size=2439\n",
      "2025-05-02 14:17:10,848 - INFO -   y_true counts: {0: 1637, 1: 802}\n",
      "2025-05-02 14:17:10,848 - INFO -   y_pred counts: {0: 1440, 1: 999}\n",
      "2025-05-02 14:17:10,849 - INFO -   ActualPos=802, ActualNeg=1637, PredictedPos=999\n",
      "2025-05-02 14:17:10,853 - INFO - DEBUG: N=8, Group=45-54: Size=1845\n",
      "2025-05-02 14:17:10,854 - INFO -   y_true counts: {0: 1124, 1: 721}\n",
      "2025-05-02 14:17:10,855 - INFO -   y_pred counts: {0: 1034, 1: 811}\n",
      "2025-05-02 14:17:10,855 - INFO -   ActualPos=721, ActualNeg=1124, PredictedPos=811\n",
      "2025-05-02 14:17:10,874 - INFO - --- Finished Budget N=8. Duration: 11.69 sec ---\n",
      "2025-05-02 14:17:10,927 - INFO - --- Processing Budget Level N = 7 ---\n",
      "2025-05-02 14:17:22,133 - INFO - Budget N=7 -> Accuracy: 0.7963\n",
      "2025-05-02 14:17:22,198 - INFO - DEBUG: N=7, Group=25-34: Size=2494\n",
      "2025-05-02 14:17:22,199 - INFO -   y_true counts: {0: 2141, 1: 353}\n",
      "2025-05-02 14:17:22,199 - INFO -   y_pred counts: {0: 1772, 1: 722}\n",
      "2025-05-02 14:17:22,200 - INFO -   ActualPos=353, ActualNeg=2141, PredictedPos=722\n",
      "2025-05-02 14:17:22,203 - INFO - DEBUG: N=7, Group=55-64: Size=1041\n",
      "2025-05-02 14:17:22,204 - INFO -   y_true counts: {0: 707, 1: 334}\n",
      "2025-05-02 14:17:22,205 - INFO -   y_pred counts: {0: 637, 1: 404}\n",
      "2025-05-02 14:17:22,205 - INFO -   ActualPos=334, ActualNeg=707, PredictedPos=404\n",
      "2025-05-02 14:17:22,213 - INFO - DEBUG: N=7, Group=35-44: Size=2439\n",
      "2025-05-02 14:17:22,213 - INFO -   y_true counts: {0: 1637, 1: 802}\n",
      "2025-05-02 14:17:22,214 - INFO -   y_pred counts: {0: 1471, 1: 968}\n",
      "2025-05-02 14:17:22,215 - INFO -   ActualPos=802, ActualNeg=1637, PredictedPos=968\n",
      "2025-05-02 14:17:22,220 - INFO - DEBUG: N=7, Group=45-54: Size=1845\n",
      "2025-05-02 14:17:22,220 - INFO -   y_true counts: {0: 1124, 1: 721}\n",
      "2025-05-02 14:17:22,221 - INFO -   y_pred counts: {0: 1034, 1: 811}\n",
      "2025-05-02 14:17:22,222 - INFO -   ActualPos=721, ActualNeg=1124, PredictedPos=811\n",
      "2025-05-02 14:17:22,243 - INFO - --- Finished Budget N=7. Duration: 11.32 sec ---\n",
      "2025-05-02 14:17:22,296 - INFO - --- Processing Budget Level N = 6 ---\n",
      "2025-05-02 14:17:33,170 - INFO - Budget N=6 -> Accuracy: 0.7768\n",
      "2025-05-02 14:17:33,231 - INFO - DEBUG: N=6, Group=25-34: Size=2494\n",
      "2025-05-02 14:17:33,232 - INFO -   y_true counts: {0: 2141, 1: 353}\n",
      "2025-05-02 14:17:33,233 - INFO -   y_pred counts: {0: 1755, 1: 739}\n",
      "2025-05-02 14:17:33,234 - INFO -   ActualPos=353, ActualNeg=2141, PredictedPos=739\n",
      "2025-05-02 14:17:33,238 - INFO - DEBUG: N=6, Group=55-64: Size=1041\n",
      "2025-05-02 14:17:33,239 - INFO -   y_true counts: {0: 707, 1: 334}\n",
      "2025-05-02 14:17:33,240 - INFO -   y_pred counts: {0: 615, 1: 426}\n",
      "2025-05-02 14:17:33,240 - INFO -   ActualPos=334, ActualNeg=707, PredictedPos=426\n",
      "2025-05-02 14:17:33,246 - INFO - DEBUG: N=6, Group=35-44: Size=2439\n",
      "2025-05-02 14:17:33,249 - INFO -   y_true counts: {0: 1637, 1: 802}\n",
      "2025-05-02 14:17:33,250 - INFO -   y_pred counts: {0: 1482, 1: 957}\n",
      "2025-05-02 14:17:33,251 - INFO -   ActualPos=802, ActualNeg=1637, PredictedPos=957\n",
      "2025-05-02 14:17:33,254 - INFO - DEBUG: N=6, Group=45-54: Size=1845\n",
      "2025-05-02 14:17:33,255 - INFO -   y_true counts: {0: 1124, 1: 721}\n",
      "2025-05-02 14:17:33,255 - INFO -   y_pred counts: {0: 1053, 1: 792}\n",
      "2025-05-02 14:17:33,256 - INFO -   ActualPos=721, ActualNeg=1124, PredictedPos=792\n",
      "2025-05-02 14:17:33,276 - INFO - --- Finished Budget N=6. Duration: 10.98 sec ---\n",
      "2025-05-02 14:17:33,331 - INFO - --- Processing Budget Level N = 5 ---\n",
      "2025-05-02 14:17:44,378 - INFO - Budget N=5 -> Accuracy: 0.7908\n",
      "2025-05-02 14:17:44,451 - INFO - DEBUG: N=5, Group=25-34: Size=2494\n",
      "2025-05-02 14:17:44,452 - INFO -   y_true counts: {0: 2141, 1: 353}\n",
      "2025-05-02 14:17:44,453 - INFO -   y_pred counts: {0: 1757, 1: 737}\n",
      "2025-05-02 14:17:44,455 - INFO -   ActualPos=353, ActualNeg=2141, PredictedPos=737\n",
      "2025-05-02 14:17:44,460 - INFO - DEBUG: N=5, Group=55-64: Size=1041\n",
      "2025-05-02 14:17:44,461 - INFO -   y_true counts: {0: 707, 1: 334}\n",
      "2025-05-02 14:17:44,463 - INFO -   y_pred counts: {0: 616, 1: 425}\n",
      "2025-05-02 14:17:44,465 - INFO -   ActualPos=334, ActualNeg=707, PredictedPos=425\n",
      "2025-05-02 14:17:44,472 - INFO - DEBUG: N=5, Group=35-44: Size=2439\n",
      "2025-05-02 14:17:44,473 - INFO -   y_true counts: {0: 1637, 1: 802}\n",
      "2025-05-02 14:17:44,474 - INFO -   y_pred counts: {0: 1482, 1: 957}\n",
      "2025-05-02 14:17:44,476 - INFO -   ActualPos=802, ActualNeg=1637, PredictedPos=957\n",
      "2025-05-02 14:17:44,481 - INFO - DEBUG: N=5, Group=45-54: Size=1845\n",
      "2025-05-02 14:17:44,483 - INFO -   y_true counts: {0: 1124, 1: 721}\n",
      "2025-05-02 14:17:44,484 - INFO -   y_pred counts: {0: 1075, 1: 770}\n",
      "2025-05-02 14:17:44,485 - INFO -   ActualPos=721, ActualNeg=1124, PredictedPos=770\n",
      "2025-05-02 14:17:44,514 - INFO - --- Finished Budget N=5. Duration: 11.18 sec ---\n",
      "2025-05-02 14:17:44,588 - INFO - --- Processing Budget Level N = 4 ---\n",
      "2025-05-02 14:17:57,077 - INFO - Budget N=4 -> Accuracy: 0.7805\n",
      "2025-05-02 14:17:57,150 - INFO - DEBUG: N=4, Group=25-34: Size=2494\n",
      "2025-05-02 14:17:57,151 - INFO -   y_true counts: {0: 2141, 1: 353}\n",
      "2025-05-02 14:17:57,152 - INFO -   y_pred counts: {0: 1861, 1: 633}\n",
      "2025-05-02 14:17:57,153 - INFO -   ActualPos=353, ActualNeg=2141, PredictedPos=633\n",
      "2025-05-02 14:17:57,158 - INFO - DEBUG: N=4, Group=55-64: Size=1041\n",
      "2025-05-02 14:17:57,159 - INFO -   y_true counts: {0: 707, 1: 334}\n",
      "2025-05-02 14:17:57,160 - INFO -   y_pred counts: {0: 645, 1: 396}\n",
      "2025-05-02 14:17:57,161 - INFO -   ActualPos=334, ActualNeg=707, PredictedPos=396\n",
      "2025-05-02 14:17:57,167 - INFO - DEBUG: N=4, Group=35-44: Size=2439\n",
      "2025-05-02 14:17:57,167 - INFO -   y_true counts: {0: 1637, 1: 802}\n",
      "2025-05-02 14:17:57,168 - INFO -   y_pred counts: {0: 1484, 1: 955}\n",
      "2025-05-02 14:17:57,169 - INFO -   ActualPos=802, ActualNeg=1637, PredictedPos=955\n",
      "2025-05-02 14:17:57,175 - INFO - DEBUG: N=4, Group=45-54: Size=1845\n",
      "2025-05-02 14:17:57,177 - INFO -   y_true counts: {0: 1124, 1: 721}\n",
      "2025-05-02 14:17:57,178 - INFO -   y_pred counts: {0: 1075, 1: 770}\n",
      "2025-05-02 14:17:57,180 - INFO -   ActualPos=721, ActualNeg=1124, PredictedPos=770\n",
      "2025-05-02 14:17:57,217 - INFO - --- Finished Budget N=4. Duration: 12.63 sec ---\n",
      "2025-05-02 14:17:57,298 - INFO - --- Processing Budget Level N = 3 ---\n",
      "2025-05-02 14:18:08,875 - INFO - Budget N=3 -> Accuracy: 0.7512\n",
      "2025-05-02 14:18:08,936 - INFO - DEBUG: N=3, Group=25-34: Size=2494\n",
      "2025-05-02 14:18:08,937 - INFO -   y_true counts: {0: 2141, 1: 353}\n",
      "2025-05-02 14:18:08,938 - INFO -   y_pred counts: {0: 1653, 1: 841}\n",
      "2025-05-02 14:18:08,939 - INFO -   ActualPos=353, ActualNeg=2141, PredictedPos=841\n",
      "2025-05-02 14:18:08,942 - INFO - DEBUG: N=3, Group=55-64: Size=1041\n",
      "2025-05-02 14:18:08,943 - INFO -   y_true counts: {0: 707, 1: 334}\n",
      "2025-05-02 14:18:08,944 - INFO -   y_pred counts: {1: 576, 0: 465}\n",
      "2025-05-02 14:18:08,945 - INFO -   ActualPos=334, ActualNeg=707, PredictedPos=576\n",
      "2025-05-02 14:18:08,951 - INFO - DEBUG: N=3, Group=35-44: Size=2439\n",
      "2025-05-02 14:18:08,952 - INFO -   y_true counts: {0: 1637, 1: 802}\n",
      "2025-05-02 14:18:08,953 - INFO -   y_pred counts: {0: 1517, 1: 922}\n",
      "2025-05-02 14:18:08,953 - INFO -   ActualPos=802, ActualNeg=1637, PredictedPos=922\n",
      "2025-05-02 14:18:08,958 - INFO - DEBUG: N=3, Group=45-54: Size=1845\n",
      "2025-05-02 14:18:08,959 - INFO -   y_true counts: {0: 1124, 1: 721}\n",
      "2025-05-02 14:18:08,959 - INFO -   y_pred counts: {0: 1097, 1: 748}\n",
      "2025-05-02 14:18:08,960 - INFO -   ActualPos=721, ActualNeg=1124, PredictedPos=748\n",
      "2025-05-02 14:18:08,978 - INFO - --- Finished Budget N=3. Duration: 11.68 sec ---\n",
      "2025-05-02 14:18:09,033 - INFO - --- Processing Budget Level N = 2 ---\n",
      "2025-05-02 14:18:19,593 - INFO - Budget N=2 -> Accuracy: 0.7467\n",
      "2025-05-02 14:18:19,657 - INFO - DEBUG: N=2, Group=25-34: Size=2494\n",
      "2025-05-02 14:18:19,658 - INFO -   y_true counts: {0: 2141, 1: 353}\n",
      "2025-05-02 14:18:19,658 - INFO -   y_pred counts: {0: 1653, 1: 841}\n",
      "2025-05-02 14:18:19,659 - INFO -   ActualPos=353, ActualNeg=2141, PredictedPos=841\n",
      "2025-05-02 14:18:19,663 - INFO - DEBUG: N=2, Group=55-64: Size=1041\n",
      "2025-05-02 14:18:19,665 - INFO -   y_true counts: {0: 707, 1: 334}\n",
      "2025-05-02 14:18:19,665 - INFO -   y_pred counts: {0: 680, 1: 361}\n",
      "2025-05-02 14:18:19,666 - INFO -   ActualPos=334, ActualNeg=707, PredictedPos=361\n",
      "2025-05-02 14:18:19,673 - INFO - DEBUG: N=2, Group=35-44: Size=2439\n",
      "2025-05-02 14:18:19,674 - INFO -   y_true counts: {0: 1637, 1: 802}\n",
      "2025-05-02 14:18:19,675 - INFO -   y_pred counts: {0: 1486, 1: 953}\n",
      "2025-05-02 14:18:19,676 - INFO -   ActualPos=802, ActualNeg=1637, PredictedPos=953\n",
      "2025-05-02 14:18:19,679 - INFO - DEBUG: N=2, Group=45-54: Size=1845\n",
      "2025-05-02 14:18:19,680 - INFO -   y_true counts: {0: 1124, 1: 721}\n",
      "2025-05-02 14:18:19,681 - INFO -   y_pred counts: {1: 1038, 0: 807}\n",
      "2025-05-02 14:18:19,682 - INFO -   ActualPos=721, ActualNeg=1124, PredictedPos=1038\n",
      "2025-05-02 14:18:19,702 - INFO - --- Finished Budget N=2. Duration: 10.67 sec ---\n",
      "2025-05-02 14:18:19,761 - INFO - --- Processing Budget Level N = 1 ---\n",
      "2025-05-02 14:18:29,641 - INFO - Budget N=1 -> Accuracy: 0.7252\n",
      "2025-05-02 14:18:29,701 - INFO - DEBUG: N=1, Group=25-34: Size=2494\n",
      "2025-05-02 14:18:29,702 - INFO -   y_true counts: {0: 2141, 1: 353}\n",
      "2025-05-02 14:18:29,702 - INFO -   y_pred counts: {0: 1608, 1: 886}\n",
      "2025-05-02 14:18:29,703 - INFO -   ActualPos=353, ActualNeg=2141, PredictedPos=886\n",
      "2025-05-02 14:18:29,707 - INFO - DEBUG: N=1, Group=55-64: Size=1041\n",
      "2025-05-02 14:18:29,708 - INFO -   y_true counts: {0: 707, 1: 334}\n",
      "2025-05-02 14:18:29,709 - INFO -   y_pred counts: {0: 734, 1: 307}\n",
      "2025-05-02 14:18:29,710 - INFO -   ActualPos=334, ActualNeg=707, PredictedPos=307\n",
      "2025-05-02 14:18:29,716 - INFO - DEBUG: N=1, Group=35-44: Size=2439\n",
      "2025-05-02 14:18:29,717 - INFO -   y_true counts: {0: 1637, 1: 802}\n",
      "2025-05-02 14:18:29,717 - INFO -   y_pred counts: {0: 1469, 1: 970}\n",
      "2025-05-02 14:18:29,718 - INFO -   ActualPos=802, ActualNeg=1637, PredictedPos=970\n",
      "2025-05-02 14:18:29,722 - INFO - DEBUG: N=1, Group=45-54: Size=1845\n",
      "2025-05-02 14:18:29,723 - INFO -   y_true counts: {0: 1124, 1: 721}\n",
      "2025-05-02 14:18:29,723 - INFO -   y_pred counts: {1: 1119, 0: 726}\n",
      "2025-05-02 14:18:29,724 - INFO -   ActualPos=721, ActualNeg=1124, PredictedPos=1119\n",
      "2025-05-02 14:18:29,741 - INFO - --- Finished Budget N=1. Duration: 9.98 sec ---\n",
      "2025-05-02 14:18:29,793 - INFO - --- Budgeting Simulation Loop Finished ---\n",
      "2025-05-02 14:18:29,794 - INFO - Total time: 101.90 seconds (1.70 minutes)\n",
      "2025-05-02 14:18:29,794 - INFO - --- Formatting and Saving Budgeting Results ---\n",
      "2025-05-02 14:18:29,798 - INFO - Attempting to save budgeting results to: budget_gridsearch_fairness_results.xlsx\n",
      "2025-05-02 14:18:29,826 - INFO - Successfully saved budgeting results to budget_gridsearch_fairness_results.xlsx\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Budgeting Results Summary ---\n",
      "   Budget (N)  Accuracy  Demographic_Parity_Disparity_age_bin  \\\n",
      "0           9    0.7995                                0.3717   \n",
      "1           8    0.7995                                0.3790   \n",
      "2           7    0.7963                                0.3790   \n",
      "3           6    0.7768                                0.2813   \n",
      "4           5    0.7908                                0.3472   \n",
      "5           4    0.7805                                0.2573   \n",
      "6           3    0.7512                                0.2997   \n",
      "7           2    0.7467                                0.4567   \n",
      "8           1    0.7252                                0.4755   \n",
      "\n",
      "   Equalized_Odds_Disparity_age_bin  Predictive_Parity_Disparity_age_bin  \\\n",
      "0                            0.2058                               0.5539   \n",
      "1                            0.1947                               0.5405   \n",
      "2                            0.1951                               0.5405   \n",
      "3                            0.3656                               0.6699   \n",
      "4                            0.3581                               0.6413   \n",
      "5                            0.3569                               0.6831   \n",
      "6                            0.4623                               0.6878   \n",
      "7                            0.4530                               0.4211   \n",
      "8                            0.4669                               0.3871   \n",
      "\n",
      "   Demographic_Parity_Disparity_race  Equalized_Odds_Disparity_race  \\\n",
      "0                             0.2101                         0.2255   \n",
      "1                             0.2023                         0.2778   \n",
      "2                             0.1989                         0.2044   \n",
      "3                             0.2061                         0.2393   \n",
      "4                             0.2048                         0.2393   \n",
      "5                             0.2033                         0.2412   \n",
      "6                             0.2227                         0.2589   \n",
      "7                             0.2335                         0.2778   \n",
      "8                             0.2181                         0.4017   \n",
      "\n",
      "   Predictive_Parity_Disparity_race  Demographic_Parity_Disparity_sex  \\\n",
      "0                            0.3110                            0.2082   \n",
      "1                            0.2927                            0.2107   \n",
      "2                            0.2820                            0.2028   \n",
      "3                            0.2973                            0.1885   \n",
      "4                            0.3201                            0.1939   \n",
      "5                            0.3153                            0.1833   \n",
      "6                            0.2125                            0.1771   \n",
      "7                            0.2554                            0.1409   \n",
      "8                            0.3068                            0.1377   \n",
      "\n",
      "   Equalized_Odds_Disparity_sex  ...  Predictive_Parity_age_bin_55-64  \\\n",
      "0                        0.1547  ...                           0.6192   \n",
      "1                        0.1393  ...                           0.6188   \n",
      "2                        0.1260  ...                           0.6163   \n",
      "3                        0.1166  ...                           0.5939   \n",
      "4                        0.1165  ...                           0.5929   \n",
      "5                        0.1110  ...                           0.6035   \n",
      "6                        0.1136  ...                           0.5000   \n",
      "7                        0.0572  ...                           0.5402   \n",
      "8                        0.0632  ...                           0.5342   \n",
      "\n",
      "   Predictive_Parity_age_bin_65plus  Predictive_Parity_age_bin_lt25  \\\n",
      "0                            0.5850                          0.1475   \n",
      "1                            0.5839                          0.1475   \n",
      "2                            0.5256                          0.1475   \n",
      "3                            0.5188                          0.0270   \n",
      "4                            0.5157                          0.0652   \n",
      "5                            0.5000                          0.0234   \n",
      "6                            0.5000                          0.0234   \n",
      "7                            0.4762                          0.1714   \n",
      "8                            0.4521                          0.1714   \n",
      "\n",
      "   Predictive_Parity_race_Amer-Indian-Eskimo  \\\n",
      "0                                     0.2609   \n",
      "1                                     0.2778   \n",
      "2                                     0.2857   \n",
      "3                                     0.2381   \n",
      "4                                     0.2381   \n",
      "5                                     0.2273   \n",
      "6                                     0.2857   \n",
      "7                                     0.2381   \n",
      "8                                     0.1600   \n",
      "\n",
      "   Predictive_Parity_race_Asian-Pac-Islander  Predictive_Parity_race_Black  \\\n",
      "0                                     0.4923                        0.4768   \n",
      "1                                     0.5078                        0.4625   \n",
      "2                                     0.4884                        0.4506   \n",
      "3                                     0.4593                        0.4337   \n",
      "4                                     0.4844                        0.4510   \n",
      "5                                     0.4769                        0.4214   \n",
      "6                                     0.4145                        0.3833   \n",
      "7                                     0.4062                        0.3676   \n",
      "8                                     0.3929                        0.3040   \n",
      "\n",
      "   Predictive_Parity_race_Other  Predictive_Parity_race_White  \\\n",
      "0                        0.5385                        0.5719   \n",
      "1                        0.5000                        0.5705   \n",
      "2                        0.4444                        0.5677   \n",
      "3                        0.3478                        0.5354   \n",
      "4                        0.4000                        0.5582   \n",
      "5                        0.3810                        0.5426   \n",
      "6                        0.3810                        0.4982   \n",
      "7                        0.4375                        0.4935   \n",
      "8                        0.3889                        0.4668   \n",
      "\n",
      "   Predictive_Parity_sex_Female  Predictive_Parity_sex_Male  \n",
      "0                        0.4226                      0.5902  \n",
      "1                        0.4339                      0.5865  \n",
      "2                        0.4209                      0.5850  \n",
      "3                        0.3627                      0.5634  \n",
      "4                        0.3997                      0.5807  \n",
      "5                        0.3651                      0.5715  \n",
      "6                        0.3190                      0.5319  \n",
      "7                        0.2873                      0.5425  \n",
      "8                        0.2619                      0.5123  \n",
      "\n",
      "[9 rows x 76 columns]\n"
     ]
    }
   ],
   "source": [
    "def create_preprocessing_pipeline(numericFeatures, categoricalFeatures):\n",
    "    \"\"\"Creates a ColumnTransformer pipeline for the given features.\"\"\"\n",
    "    transformers = []\n",
    "    if numericFeatures:\n",
    "        numPipe = Pipeline([('imp', SimpleImputer(strategy='mean')), ('scale', StandardScaler())])\n",
    "        transformers.append(('num', numPipe, numericFeatures)) \n",
    "    if categoricalFeatures:\n",
    "        catPipe = Pipeline([('imp', SimpleImputer(strategy='most_frequent')), ('ohe', OneHotEncoder(handle_unknown='ignore', sparse_output=False))])\n",
    "        transformers.append(('cat', catPipe, categoricalFeatures)) \n",
    "    if not transformers:\n",
    "        logging.warning(\"create_preprocessing_pipeline called with no features.\")\n",
    "        return ColumnTransformer(transformers=[], remainder='drop') \n",
    "    preprocessor = ColumnTransformer(transformers=transformers, remainder='drop', verbose_feature_names_out=False)\n",
    "    preprocessor.set_output(transform=\"pandas\") \n",
    "    return preprocessor\n",
    "\n",
    "# Data Loading and Preparation\n",
    "logging.info(\"--- Starting Data Loading and Preparation ---\")\n",
    "try:\n",
    "    dfFull = pd.read_csv(datasetPath)\n",
    "    logging.info(f\"Successfully loaded dataset: {datasetPath}. Shape: {dfFull.shape}\")\n",
    "except FileNotFoundError:\n",
    "    logging.error(f\"Dataset file not found at: {datasetPath}\")\n",
    "    raise\n",
    "except Exception as e:\n",
    "    logging.error(f\"Error loading dataset: {e}\")\n",
    "    raise\n",
    "\n",
    "dfFull.columns = dfFull.columns.str.strip()\n",
    "dfFull.columns = dfFull.columns.str.replace('-', '_', regex=False).str.replace(' ', '_', regex=False)\n",
    "\n",
    "for col in dfFull.select_dtypes(include=['object']).columns:\n",
    "    if col in dfFull.columns: \n",
    "        try:\n",
    "            dfFull[col] = dfFull[col].str.strip()\n",
    "            dfFull[col] = dfFull[col].replace(['?', 'N/A', '', 'None'], np.nan)\n",
    "        except AttributeError:\n",
    "            logging.warning(f\"Could not apply string operations to column '{col}'.\")\n",
    "\n",
    "essentialCols = [targetColumn] + protectedAttributesOriginal \n",
    "missingEssentials = [col for col in essentialCols if col not in dfFull.columns]\n",
    "if missingEssentials:\n",
    "    raise ValueError(f\"Essential columns missing from dataset: {missingEssentials}\")\n",
    "\n",
    "uniqueTargets = dfFull[targetColumn].unique()\n",
    "if len(uniqueTargets) > 2:\n",
    "    if '<=50K' in uniqueTargets and '>50K' in uniqueTargets:\n",
    "        targetMap = {'<=50K': 0, '>50K': 1}\n",
    "        dfFull[targetColumn] = dfFull[targetColumn].map(targetMap)\n",
    "    elif len(uniqueTargets) == 2:\n",
    "        logging.warning(f\"Target values not '<=50K', '>50K'. Mapping '{uniqueTargets[0]}'->0, '{uniqueTargets[1]}'->1.\")\n",
    "        targetMap = {uniqueTargets[0]: 0, uniqueTargets[1]: 1}\n",
    "        dfFull[targetColumn] = dfFull[targetColumn].map(targetMap)\n",
    "    else: raise ValueError(f\"Target '{targetColumn}' has > 2 unique values: {uniqueTargets}\")\n",
    "elif len(uniqueTargets) == 1: raise ValueError(f\"Target '{targetColumn}' has only one value: {uniqueTargets[0]}.\")\n",
    "elif not set(uniqueTargets).issubset({0, 1}):\n",
    "     logging.warning(f\"Target values binary but not 0/1 ({uniqueTargets}). Mapping '{uniqueTargets[0]}'->0, '{uniqueTargets[1]}'->1.\")\n",
    "     targetMap = {uniqueTargets[0]: 0, uniqueTargets[1]: 1}\n",
    "     dfFull[targetColumn] = dfFull[targetColumn].map(targetMap)\n",
    "\n",
    "if dfFull[targetColumn].isnull().any():\n",
    "    nanCount = dfFull[targetColumn].isnull().sum()\n",
    "    logging.warning(f\"{nanCount} rows have NaN target. Dropping.\")\n",
    "    rowsBefore = len(dfFull)\n",
    "    dfFull.dropna(subset=[targetColumn], inplace=True)\n",
    "dfFull[targetColumn] = dfFull[targetColumn].astype(int)\n",
    "\n",
    "dfProcessed = apply_age_binning(dfFull, ageColumn, binnedAgeColumnName, defaultAgeBins, defaultAgeLabels)\n",
    "\n",
    "protectedAttributesAnalysis = [binnedAgeColumnName if p == ageColumn else p for p in protectedAttributesOriginal]\n",
    "logging.info(f\"Protected attributes for analysis: {protectedAttributesAnalysis}\")\n",
    "\n",
    "potentialFeatureCols = [col for col in dfProcessed.columns if col != targetColumn and col not in protectedAttributesOriginal and col != binnedAgeColumnName]\n",
    "logging.info(f\"Identified {len(potentialFeatureCols)} potential features for model.\")\n",
    "\n",
    "essentialAnalysisCols = [targetColumn] + protectedAttributesAnalysis \n",
    "rowsBeforeNa = len(dfProcessed)\n",
    "dfProcessed.dropna(subset=protectedAttributesAnalysis, inplace=True) \n",
    "rowsAfterNa = len(dfProcessed)\n",
    "if rowsAfterNa < rowsBeforeNa:\n",
    "    logging.warning(f\"Dropped {rowsBeforeNa - rowsAfterNa} rows due to missing protected attributes.\")\n",
    "\n",
    "if dfProcessed.empty: raise ValueError(\"DataFrame empty after NA handling.\")\n",
    "logging.info(f\"Final dataset shape before split: {dfProcessed.shape}\")\n",
    "\n",
    "x = dfProcessed[potentialFeatureCols]\n",
    "y = dfProcessed[targetColumn]\n",
    "p = dfProcessed[protectedAttributesAnalysis] \n",
    "\n",
    "stratifyOption = y if y.nunique() > 1 and y.value_counts().min() >= 2 else None\n",
    "xTrainOrig, xTestOrig, yTrain, yTest, pTrain, pTest = train_test_split(\n",
    "    x, y, p, test_size=testSize, random_state=randomState, stratify=stratifyOption)\n",
    "\n",
    "logging.info(f\"Data split complete: Train={len(yTrain)}, Test={len(yTest)}\")\n",
    "# Print test set distribution for age_bin\n",
    "logging.info(\"--- Test Set Distribution for age_bin ---\")\n",
    "if binnedAgeColumnName in pTest.columns:\n",
    "    print(pTest[binnedAgeColumnName].value_counts())\n",
    "else:\n",
    "    logging.warning(f\"Column '{binnedAgeColumnName}' not found in pTest.\")\n",
    "logging.info(\"-----------------------------------------\")\n",
    "\n",
    "del dfFull, dfProcessed, x, y, p \n",
    "gc.collect()\n",
    "\n",
    "# Step 1: Preprocess Data and Train Global Model \n",
    "logging.info(\"--- Preprocessing Data and Training Global Model ---\")\n",
    "\n",
    "numericFeatures = xTrainOrig.select_dtypes(include=np.number).columns.tolist()\n",
    "categoricalFeatures = xTrainOrig.select_dtypes(exclude=np.number).columns.tolist()\n",
    "\n",
    "globalPreprocessor = create_preprocessing_pipeline(numericFeatures, categoricalFeatures)\n",
    "\n",
    "logging.info(\"Fitting global preprocessor...\")\n",
    "xTrainProcessed = globalPreprocessor.fit_transform(xTrainOrig)\n",
    "processedFeatureNames = globalPreprocessor.get_feature_names_out()\n",
    "logging.info(f\"Preprocessing complete. Processed training features shape: {xTrainProcessed.shape}\")\n",
    "\n",
    "logging.info(\"Training global Logistic Regression model...\")\n",
    "globalModel = LogisticRegression(**lrParams)\n",
    "globalModel.fit(xTrainProcessed, yTrain)\n",
    "logging.info(\"Global model training complete.\")\n",
    "\n",
    "# Step 2: Calculate Permutation Importance per Subgroup ---\n",
    "logging.info(\"--- Calculating Permutation Importance per Subgroup ---\")\n",
    "startTimePI = time.time()\n",
    "\n",
    "groupImportances = {} \n",
    "\n",
    "for paColName in protectedAttributesAnalysis:\n",
    "    logging.info(f\"Calculating PI for subgroups in: {paColName}\")\n",
    "    groupImportances[paColName] = {}\n",
    "    if not pTrain.index.equals(xTrainProcessed.index):\n",
    "        logging.warning(f\"Re-indexing pTrain for {paColName} PI calculation.\")\n",
    "        pTrain = pTrain.reindex(xTrainProcessed.index)\n",
    "        \n",
    "    uniqueGroupsTrain = pTrain[paColName].unique()\n",
    "    logging.info(f\"Found groups in training data for {paColName}: {uniqueGroupsTrain}\")\n",
    "\n",
    "    for groupName in uniqueGroupsTrain:\n",
    "        groupNameStr = str(groupName) if pd.notna(groupName) else \"NaN_Group\"\n",
    "        \n",
    "        # Use original groupName for masking\n",
    "        if pd.isna(groupName):\n",
    "            mask = pTrain[paColName].isnull()\n",
    "        else:\n",
    "            mask = (pTrain[paColName] == groupName)\n",
    "\n",
    "        xGroup = xTrainProcessed[mask]\n",
    "        yGroup = yTrain[mask]\n",
    "        \n",
    "        if len(xGroup) < minSamplesForPI:\n",
    "            logging.warning(f\"Skipping PI for {paColName}/{groupNameStr}: Too few samples ({len(xGroup)} < {minSamplesForPI}).\")\n",
    "            groupImportances[paColName][groupNameStr] = [] \n",
    "            continue\n",
    "            \n",
    "        if yGroup.nunique() < 2:\n",
    "            logging.warning(f\"Skipping PI for {paColName}/{groupNameStr}: Only one target class present.\")\n",
    "            groupImportances[paColName][groupNameStr] = []\n",
    "            continue\n",
    "            \n",
    "        try:\n",
    "            piResult = permutation_importance(\n",
    "                globalModel, xGroup, yGroup, \n",
    "                n_repeats=piNRepeats, random_state=randomState, \n",
    "                n_jobs=piNJobs, scoring='accuracy' \n",
    "            )\n",
    "            \n",
    "            importancesMean = piResult.importances_mean\n",
    "            sortedIndices = np.argsort(importancesMean)[::-1]\n",
    "            \n",
    "            sortedImportances = [\n",
    "                (processedFeatureNames[i], importancesMean[i]) \n",
    "                for i in sortedIndices if importancesMean[i] > 1e-6 \n",
    "            ]\n",
    "            \n",
    "            groupImportances[paColName][groupNameStr] = sortedImportances\n",
    "            if sortedImportances:\n",
    "                 logging.debug(f\"PI completed for {paColName}/{groupNameStr}. Top feature: {sortedImportances[0]}\")\n",
    "            else:\n",
    "                 logging.warning(f\"No significant features found via PI for {paColName}/{groupNameStr}.\")\n",
    "\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error calculating PI for {paColName}/{groupNameStr}: {e}\", exc_info=True)\n",
    "            groupImportances[paColName][groupNameStr] = [] \n",
    "\n",
    "piDuration = time.time() - startTimePI\n",
    "logging.info(f\"--- Permutation Importance Calculation Finished. Duration: {piDuration:.2f} sec ---\")\n",
    "\n",
    "del xGroup, yGroup \n",
    "gc.collect()\n",
    "\n",
    "# tep 3: Iterate Through Budgets, Train Group Models, Predict, Evaluate\n",
    "logging.info(\"--- Starting Budgeting Simulation Loop ---\")\n",
    "startTimeBudgetLoop = time.time()\n",
    "\n",
    "allBudgetResults = []\n",
    "processedFeatureNamesList = list(processedFeatureNames) \n",
    "\n",
    "logging.info(\"Preprocessing test data...\")\n",
    "xTestProcessed = globalPreprocessor.transform(xTestOrig)\n",
    "xTestProcessed = pd.DataFrame(xTestProcessed, index=xTestOrig.index, columns=processedFeatureNames) \n",
    "logging.info(f\"Test data preprocessed. Shape: {xTestProcessed.shape}\")\n",
    "\n",
    "for nFeaturesBudget in range(maxBudgetFeatures, minBudgetFeatures - 1, -1):\n",
    "    iterationStartTime = time.time()\n",
    "    logging.info(f\"--- Processing Budget Level N = {nFeaturesBudget} ---\")\n",
    "    \n",
    "    # Train Group-Specific Models for this Budget N\n",
    "    groupModels = {} \n",
    "    groupFeaturesUsed = {} \n",
    "    \n",
    "    logging.debug(f\"Training group models for N={nFeaturesBudget}...\")\n",
    "    for paColName, groups in groupImportances.items():\n",
    "        groupModels[paColName] = {}\n",
    "        groupFeaturesUsed[paColName] = {}\n",
    "        for groupNameStr, importances in groups.items():\n",
    "            if not importances: \n",
    "                logging.debug(f\"Skipping model training for {paColName}/{groupNameStr} (N={nFeaturesBudget}): No importance scores.\")\n",
    "                continue\n",
    "\n",
    "            topNFeatures = [feat for feat, score in importances[:nFeaturesBudget]]\n",
    "            groupFeaturesUsed[paColName][groupNameStr] = topNFeatures\n",
    "            \n",
    "            if not topNFeatures:\n",
    "                logging.warning(f\"Skipping model training for {paColName}/{groupNameStr} (N={nFeaturesBudget}): No features selected.\")\n",
    "                continue\n",
    "\n",
    "            missingFeatures = [f for f in topNFeatures if f not in processedFeatureNamesList]\n",
    "            if missingFeatures:\n",
    "                 logging.error(f\"FATAL ERROR training {paColName}/{groupNameStr} (N={nFeaturesBudget}): Budgeted features {missingFeatures} not found. Skipping group model.\")\n",
    "                 topNFeatures = [f for f in topNFeatures if f in processedFeatureNamesList]\n",
    "                 groupFeaturesUsed[paColName][groupNameStr] = topNFeatures \n",
    "                 if not topNFeatures: continue \n",
    "            \n",
    "            # Re-create mask to get group training data using original groupName value logic from PI loop\n",
    "            mask = pd.Series(False, index=pTrain.index) # Default to False\n",
    "            matched = False\n",
    "            originalGroupNameValue = None # Variable to store the original value that matches groupNameStr\n",
    "\n",
    "            if groupNameStr == \"NaN_Group\":\n",
    "                 mask = pTrain[paColName].isnull()\n",
    "                 matched = True\n",
    "                 originalGroupNameValue = np.nan # Represent NaN group\n",
    "            else:\n",
    "                 # Find the original value in pTrain corresponding to groupNameStr\n",
    "                 for uniqueVal in pTrain[paColName].unique():\n",
    "                     currentGroupNameStr = str(uniqueVal) if pd.notna(uniqueVal) else \"NaN_Group\"\n",
    "                     if currentGroupNameStr == groupNameStr:\n",
    "                          mask = (pTrain[paColName] == uniqueVal)\n",
    "                          originalGroupNameValue = uniqueVal # Store the matching value\n",
    "                          matched = True\n",
    "                          break\n",
    "            if not matched: \n",
    "                # This case should be rare if groupNameStr came directly from unique values\n",
    "                logging.error(f\"Could not find original group value matching '{groupNameStr}' for {paColName}. Skipping model training.\")\n",
    "                continue\n",
    "                 \n",
    "            xGroupTrain = xTrainProcessed.loc[mask, topNFeatures] \n",
    "            yGroupTrain = yTrain[mask]\n",
    "            \n",
    "            if len(xGroupTrain) < 5: \n",
    "                logging.warning(f\"Skipping model training for {paColName}/{groupNameStr} (N={nFeaturesBudget}): Too few samples ({len(xGroupTrain)}).\")\n",
    "                continue\n",
    "            if yGroupTrain.nunique() < 2:\n",
    "                logging.warning(f\"Skipping model training for {paColName}/{groupNameStr} (N={nFeaturesBudget}): Only one target class.\")\n",
    "                continue\n",
    "                \n",
    "            try:\n",
    "                groupClf = LogisticRegression(**lrParams)\n",
    "                groupClf.fit(xGroupTrain, yGroupTrain)\n",
    "                groupModels[paColName][groupNameStr] = groupClf\n",
    "            except Exception as e:\n",
    "                logging.error(f\"Error training group model for {paColName}/{groupNameStr} (N={nFeaturesBudget}): {e}\", exc_info=True)\n",
    "\n",
    "    # Predict on Test Set using Group Models (Row-by-Row)\n",
    "    logging.debug(f\"Predicting using group models for N={nFeaturesBudget}...\")\n",
    "    yPredCombined = []\n",
    "    modelUsedCounts = {'global_fallback': 0} \n",
    "\n",
    "    if not pTest.index.equals(xTestProcessed.index):\n",
    "         logging.warning(\"Re-indexing pTest before prediction loop.\")\n",
    "         pTest = pTest.reindex(xTestProcessed.index)\n",
    "\n",
    "    for idx in xTestProcessed.index:\n",
    "        rowData = xTestProcessed.loc[[idx]] \n",
    "        \n",
    "        try:\n",
    "            pInfo = pTest.loc[idx]\n",
    "        except KeyError:\n",
    "             logging.error(f\"Index {idx} not found in pTest. Predicting with global model.\")\n",
    "             pred = globalModel.predict(rowData[processedFeatureNamesList])[0] \n",
    "             yPredCombined.append(pred)\n",
    "             modelUsedCounts['global_fallback'] += 1\n",
    "             continue\n",
    "\n",
    "        modelToUse = globalModel\n",
    "        featuresToUse = processedFeatureNamesList \n",
    "        modelTypeUsed = \"global_fallback\"\n",
    "\n",
    "        for paColName in protectedAttributesAnalysis: \n",
    "            groupVal = pInfo.get(paColName, None)\n",
    "            groupValStr = str(groupVal) if pd.notna(groupVal) else \"NaN_Group\"\n",
    "            \n",
    "            if paColName in groupModels and groupValStr in groupModels[paColName]:\n",
    "                modelToUse = groupModels[paColName][groupValStr]\n",
    "                featuresToUse = groupFeaturesUsed[paColName][groupValStr]\n",
    "                modelTypeUsed = f\"{paColName}_{groupValStr}\"\n",
    "                \n",
    "                if not all(f in rowData.columns for f in featuresToUse):\n",
    "                     logging.error(f\"Prediction Error: Features { [f for f in featuresToUse if f not in rowData.columns] } missing for group {modelTypeUsed} at index {idx}. Falling back to global model.\")\n",
    "                     modelToUse = globalModel \n",
    "                     featuresToUse = processedFeatureNamesList\n",
    "                     modelTypeUsed = \"global_fallback\"\n",
    "                break \n",
    "\n",
    "        try:\n",
    "            dataForPred = rowData[featuresToUse] \n",
    "            if dataForPred.empty and not featuresToUse: \n",
    "                 pred = 0 \n",
    "                 logging.warning(f\"Predicting default (0) for index {idx} due to 0 features for model {modelTypeUsed}\")\n",
    "            elif dataForPred.shape[1] != len(featuresToUse):\n",
    "                 logging.error(f\"Prediction Error: Shape mismatch for index {idx}, model {modelTypeUsed}. Expected {len(featuresToUse)} features, got {dataForPred.shape[1]}. Falling back to global.\")\n",
    "                 dataForPred = rowData[processedFeatureNamesList] \n",
    "                 pred = globalModel.predict(dataForPred)[0]\n",
    "                 modelTypeUsed = \"global_fallback\" \n",
    "            else:\n",
    "                 pred = modelToUse.predict(dataForPred)[0]\n",
    "                 \n",
    "            yPredCombined.append(pred)\n",
    "            modelUsedCounts[modelTypeUsed] = modelUsedCounts.get(modelTypeUsed, 0) + 1\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Prediction failed for index {idx} using model {modelTypeUsed}: {e}. Appending 0.\", exc_info=False) \n",
    "            yPredCombined.append(0) \n",
    "            modelUsedCounts[\"error\"] = modelUsedCounts.get(\"error\", 0) + 1\n",
    "\n",
    "    logging.debug(f\"Prediction counts for N={nFeaturesBudget}: {modelUsedCounts}\")\n",
    "    \n",
    "    # Evaluate Accuracy and Fairness for this Budget Level\n",
    "    if len(yPredCombined) != len(yTest):\n",
    "         logging.error(f\"FATAL ERROR: Length mismatch for N={nFeaturesBudget}. yPredCombined ({len(yPredCombined)}) != yTest ({len(yTest)}). Skipping.\")\n",
    "         continue \n",
    "\n",
    "    accuracy = accuracy_score(yTest, yPredCombined)\n",
    "    logging.info(f\"Budget N={nFeaturesBudget} -> Accuracy: {accuracy:.4f}\")\n",
    "    \n",
    "    # Define Placeholder Keys \n",
    "    placeholder_keys = {'Budget (N)', 'Accuracy'}\n",
    "    # Disparity Keys\n",
    "    for pa in protectedAttributesAnalysis:\n",
    "        for metric in metricsForOverallDisparity:\n",
    "             placeholder_keys.add(f\"{metric.replace(' ', '_')}_Disparity_{pa}\")\n",
    "    # Subgroup Metric Keys - based on TEST SET unique values\n",
    "    for pa in protectedAttributesAnalysis:\n",
    "        unique_groups_in_test = pTest[pa].unique() # Use test set unique values!\n",
    "        for group in unique_groups_in_test:\n",
    "             groupStr = str(group) if pd.notna(group) else \"NaN_Group\"\n",
    "             # Apply consistent sanitization\n",
    "             groupStrKey = groupStr.replace('<','lt').replace('+','plus').replace(' ','_').replace('=','eq').replace('.','_') \n",
    "             for fm in fairnessMetricsSubgroup:\n",
    "                  fmKeyPart = fm.replace(' ', '_')\n",
    "                  placeholder_keys.add(f\"{fmKeyPart}_{pa}_{groupStrKey}\")\n",
    "                  \n",
    "    resultsRow = {key: np.nan for key in placeholder_keys} # Initialize all expected keys to NaN\n",
    "    resultsRow['Budget (N)'] = nFeaturesBudget\n",
    "    resultsRow['Accuracy'] = round(accuracy, 4)\n",
    "    placeholder_keys_generated = set(resultsRow.keys()) # Track keys we expect\n",
    "  \n",
    "\n",
    "    resultsDfTemp = pTest.copy()\n",
    "    resultsDfTemp['y_true'] = yTest\n",
    "    resultsDfTemp['y_pred'] = yPredCombined \n",
    "\n",
    "    calculated_keys_found = set() # Track keys we actually calculate\n",
    "\n",
    "    for paColName in protectedAttributesAnalysis:\n",
    "        metricsForDisparityCalc = {m: [] for m in ['Demographic Parity', 'Equalized Odds', 'FPR', 'Predictive Parity']} \n",
    "        uniqueGroupsTest = resultsDfTemp[paColName].unique() # Groups actually present in this calculation run\n",
    "\n",
    "        for groupName in uniqueGroupsTest: # Use original group value for filtering\n",
    "            groupNameStr = str(groupName) if pd.notna(groupName) else \"NaN_Group\" \n",
    "            \n",
    "            # Use original groupName for filtering test data\n",
    "            if pd.isna(groupName):\n",
    "                 groupDf = resultsDfTemp[resultsDfTemp[paColName].isnull()]\n",
    "            else:\n",
    "                 groupDf = resultsDfTemp[resultsDfTemp[paColName] == groupName] \n",
    "\n",
    "            # Debugging\n",
    "            if paColName == binnedAgeColumnName and groupNameStr in ['25-34', '35-44', '45-54', '55-64']:\n",
    "                 logging.info(f\"DEBUG: N={nFeaturesBudget}, Group={groupNameStr}: Size={len(groupDf)}\")\n",
    "                 if not groupDf.empty:\n",
    "                      logging.info(f\"  y_true counts: {groupDf['y_true'].value_counts().to_dict()}\")\n",
    "                      logging.info(f\"  y_pred counts: {groupDf['y_pred'].value_counts().to_dict()}\")\n",
    "                      actualPositive = (groupDf['y_true'] == 1).sum()\n",
    "                      actualNegative = (groupDf['y_true'] == 0).sum()\n",
    "                      predictedPositive = (groupDf['y_pred'] == 1).sum()\n",
    "                      logging.info(f\"  ActualPos={actualPositive}, ActualNeg={actualNegative}, PredictedPos={predictedPositive}\")\n",
    "                 else:\n",
    "                      logging.info(\"  groupDf is empty.\")\n",
    "            # End Debugging\n",
    "            \n",
    "            metrics = calculate_fairness_metrics(groupDf)\n",
    "            \n",
    "            # Apply consistent sanitization for key construction\n",
    "            groupStrKey = groupNameStr.replace('<','lt').replace('+','plus').replace(' ','_').replace('=','eq').replace('.','_') \n",
    "\n",
    "            for fmKey, fmValue in metrics.items():\n",
    "                fmKeyPart = fmKey.replace(' ', '_')\n",
    "                colNameKey = f\"{fmKeyPart}_{paColName}_{groupStrKey}\" # Construct standard key\n",
    "                calculated_keys_found.add(colNameKey) # Track this key\n",
    "\n",
    "                if colNameKey in resultsRow: # Check against pre-defined placeholders\n",
    "                     resultsRow[colNameKey] = round(fmValue, 4) if pd.notna(fmValue) else np.nan\n",
    "                else:\n",
    "                     # This indicates a mismatch (e.g., a group appeared in calc but not in pTest unique groups used for placeholders)\n",
    "                     logging.error(f\"Key Mismatch/Unexpected Group Error! N={nFeaturesBudget}: Calculated key '{colNameKey}' not found in placeholder keys. Adding dynamically.\")\n",
    "                     resultsRow[colNameKey] = round(fmValue, 4) if pd.notna(fmValue) else np.nan\n",
    "\n",
    "            # Collect for disparity\n",
    "            if metrics['Group Size'] > 0:\n",
    "                 for metricKeyInternal in metricsForDisparityCalc.keys():\n",
    "                      if pd.notna(metrics[metricKeyInternal]): \n",
    "                          metricsForDisparityCalc[metricKeyInternal].append(metrics[metricKeyInternal])\n",
    "\n",
    "        # Calculate disparity scores\n",
    "        for metricDisp in metricsForOverallDisparity:\n",
    "            overallScore = np.nan\n",
    "            if metricDisp == 'Equalized Odds':\n",
    "                 tprRates = metricsForDisparityCalc.get('Equalized Odds', []) \n",
    "                 fprRates = metricsForDisparityCalc.get('FPR', [])\n",
    "                 tprDiff = max(tprRates) - min(tprRates) if len(tprRates) > 1 else 0.0\n",
    "                 fprDiff = max(fprRates) - min(fprRates) if len(fprRates) > 1 else 0.0\n",
    "                 validDiffs = [d for d in [tprDiff, fprDiff] if pd.notna(d)]\n",
    "                 overallScore = max(validDiffs) if validDiffs else np.nan\n",
    "            else:\n",
    "                 rates = metricsForDisparityCalc.get(metricDisp, [])\n",
    "                 if len(rates) > 1: overallScore = max(rates) - min(rates)\n",
    "            disparityKey = f\"{metricDisp.replace(' ', '_')}_Disparity_{paColName}\"\n",
    "            # Check if disparityKey exists before assigning (it should from placeholder logic)\n",
    "            if disparityKey in resultsRow:\n",
    "                resultsRow[disparityKey] = round(overallScore, 4) if pd.notna(overallScore) else np.nan\n",
    "            else:\n",
    "                 logging.error(f\"Disparity Key Error! N={nFeaturesBudget}: Disparity key '{disparityKey}' not found in placeholder keys.\")\n",
    "\n",
    "\n",
    "    # Check for missing keys after loop\n",
    "    missing_keys = placeholder_keys_generated - calculated_keys_found - set(['Budget (N)', 'Accuracy']) # Exclude non-metric keys\n",
    "    # Filter out disparity keys as they are calculated differently & checked above\n",
    "    missing_keys = {k for k in missing_keys if '_Disparity_' not in k} \n",
    "    if missing_keys:\n",
    "         logging.warning(f\"N={nFeaturesBudget}: Some expected subgroup metric keys were never calculated/found: {sorted(list(missing_keys))}\")\n",
    "\n",
    "    allBudgetResults.append(resultsRow)\n",
    "    iterationDuration = time.time() - iterationStartTime\n",
    "    logging.info(f\"--- Finished Budget N={nFeaturesBudget}. Duration: {iterationDuration:.2f} sec ---\")\n",
    "    \n",
    "    del groupModels, groupFeaturesUsed, yPredCombined, resultsDfTemp\n",
    "    gc.collect()\n",
    "\n",
    "budgetLoopDuration = time.time() - startTimeBudgetLoop\n",
    "logging.info(f\"--- Budgeting Simulation Loop Finished ---\")\n",
    "logging.info(f\"Total time: {budgetLoopDuration:.2f} seconds ({budgetLoopDuration/60:.2f} minutes)\")\n",
    "\n",
    "# Step 4: Format and Save Budgeting Results ---\n",
    "logging.info(\"--- Formatting and Saving Budgeting Results ---\")\n",
    "\n",
    "if not allBudgetResults:\n",
    "    logging.warning(\"No budgeting results were generated. Skipping saving.\")\n",
    "else:\n",
    "    resultsDf = pd.DataFrame(allBudgetResults)\n",
    "    \n",
    "    # Define column order using standard names\n",
    "    colsOrder = ['Budget (N)', 'Accuracy'] \n",
    "    for paColName in protectedAttributesAnalysis:\n",
    "        for metric in metricsForOverallDisparity:\n",
    "            colsOrder.append(f\"{metric.replace(' ', '_')}_Disparity_{paColName}\")\n",
    "            \n",
    "    # Get all keys from the first results row (assuming all rows have the same keys after robust placeholder generation)\n",
    "    all_keys = set(resultsDf.columns)\n",
    "    remainingCols = sorted(list(all_keys - set(colsOrder))) # Find remaining subgroup keys\n",
    "        \n",
    "    finalCols = colsOrder + remainingCols\n",
    "    \n",
    "    # Ensure all expected columns exist in the dataframe before reordering\n",
    "    finalCols = [col for col in finalCols if col in resultsDf.columns]\n",
    "    \n",
    "    resultsDf = resultsDf[finalCols]\n",
    "    resultsDf.sort_values(by='Budget (N)', ascending=False, inplace=True)\n",
    "\n",
    "    try:\n",
    "        logging.info(f\"Attempting to save budgeting results to: {outputExcelFile}\")\n",
    "        resultsDf.to_excel(outputExcelFile, index=False, engine='openpyxl')\n",
    "        logging.info(f\"Successfully saved budgeting results to {outputExcelFile}\")\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Failed to save budgeting results to Excel: {e}\", exc_info=True)\n",
    "        try:\n",
    "             csvFallbackPath = outputExcelFile.replace('.xlsx', '.csv')\n",
    "             logging.warning(f\"Saving budgeting results as CSV fallback: {csvFallbackPath}\")\n",
    "             resultsDf.to_csv(csvFallbackPath, index=False)\n",
    "             logging.info(f\"Successfully saved budgeting results to {csvFallbackPath}\")\n",
    "        except Exception as csvE:\n",
    "             logging.error(f\"Failed to save budgeting results to CSV as fallback: {csvE}\", exc_info=True)\n",
    "\n",
    "print(\"\\n--- Budgeting Results Summary ---\")\n",
    "print(resultsDf)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
