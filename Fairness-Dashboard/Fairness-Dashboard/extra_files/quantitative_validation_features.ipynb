{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "import os\n",
    "import logging\n",
    "import time\n",
    "import gc\n",
    "import math\n",
    "import json \n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasetPath = '../flask_ml/data/Income_dataset.csv'  \n",
    "outputExcelFile = 'feature_gridsearch_fairness_results.xlsx'\n",
    "targetColumn = 'Income' \n",
    "protectedAttributesOriginal = ['age', 'race', 'sex']\n",
    "\n",
    "ageColumn = 'age'\n",
    "binnedAgeColumnName = 'age_bin'\n",
    "defaultAgeBins = [0, 24, 34, 44, 54, 64, np.inf]\n",
    "defaultAgeLabels = ['<25', '25-34', '35-44', '45-54', '55-64', '65+']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "testSize = 0.20\n",
    "randomState = 42\n",
    "lrParams = {'C': 1.0, 'solver': 'lbfgs', 'max_iter': 1000, 'random_state': randomState, 'class_weight': 'balanced'} \n",
    "minFeaturesCombinationSize = 1 \n",
    "maxFeaturesCombinationSize = 9\n",
    "includeFullFeatureSet = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "fairnessMetricsSubgroup = ['Demographic Parity', 'Equalized Odds', 'FPR', 'Predictive Parity', 'Group Size']\n",
    "metricsForOverallDisparity = ['Demographic Parity', 'Equalized Odds', 'Predictive Parity'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logProgressEveryN = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_fairness_metrics(dfGroup):\n",
    "    \"\"\"Calculates fairness metrics for a given subgroup DataFrame.\"\"\"\n",
    "    if dfGroup.empty:\n",
    "        return {'Demographic Parity': np.nan, 'Equalized Odds': np.nan, 'FPR': np.nan, 'Predictive Parity': np.nan, 'Group Size': 0}\n",
    "\n",
    "    yTrue = dfGroup['y_true'].astype(int)\n",
    "    yPred = dfGroup['y_pred'].astype(int)\n",
    "    \n",
    "    tp = ((yTrue == 1) & (yPred == 1)).sum()\n",
    "    fp = ((yTrue == 0) & (yPred == 1)).sum()\n",
    "    tn = ((yTrue == 0) & (yPred == 0)).sum()\n",
    "    fn = ((yTrue == 1) & (yPred == 0)).sum()\n",
    "\n",
    "    predictedPositive = tp + fp\n",
    "    actualPositive = tp + fn\n",
    "    actualNegative = tn + fp\n",
    "    totalGroup = tp + fp + tn + fp \n",
    "\n",
    "    dpRate = predictedPositive / totalGroup if totalGroup > 0 else np.nan\n",
    "    tprRate = tp / actualPositive if actualPositive > 0 else np.nan \n",
    "    fprRate = fp / actualNegative if actualNegative > 0 else np.nan\n",
    "    ppRate = tp / predictedPositive if predictedPositive > 0 else np.nan\n",
    "\n",
    "    return {'Demographic Parity': dpRate,\n",
    "            'Equalized Odds': tprRate, \n",
    "            'FPR': fprRate,           \n",
    "            'Predictive Parity': ppRate,\n",
    "            'Group Size': totalGroup}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_age_binning(df, ageCol, binnedColName, bins, labels):\n",
    "    \"\"\"Applies binning to the specified age column.\"\"\"\n",
    "    dfBinned = df.copy()\n",
    "    if ageCol in dfBinned.columns and pd.api.types.is_numeric_dtype(dfBinned[ageCol]):\n",
    "        logging.info(f\"Attempting to bin numeric column '{ageCol}' into '{binnedColName}'.\")\n",
    "        try:\n",
    "             dfBinned[binnedColName] = pd.cut(dfBinned[ageCol], bins=bins, labels=labels, right=False, include_lowest=True)\n",
    "             dfBinned[binnedColName] = dfBinned[binnedColName].astype(str).fillna('NaN_Age_Bin')\n",
    "             logging.info(f\"Successfully binned '{ageCol}' into '{binnedColName}'. Unique values: {dfBinned[binnedColName].unique()}\")\n",
    "        except Exception as binErr:\n",
    "             logging.error(f\"Error binning age column '{ageCol}': {binErr}\", exc_info=True)\n",
    "             raise ValueError(f\"Failed to bin age column '{ageCol}'. Cannot proceed.\") from binErr\n",
    "    elif ageCol in dfBinned.columns:\n",
    "         logging.warning(f\"Column '{ageCol}' exists but is not numeric. Skipping binning.\")\n",
    "         dfBinned[binnedColName] = dfBinned[ageCol].astype(str).fillna('NaN_Age_Str')\n",
    "         logging.info(f\"Converted non-numeric '{ageCol}' to string as '{binnedColName}'.\")\n",
    "    else:\n",
    "        logging.error(f\"Age column '{ageCol}' not found in DataFrame. Cannot perform binning.\")\n",
    "        raise ValueError(f\"Required age column '{ageCol}' not found.\")\n",
    "\n",
    "    return dfBinned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-02 10:44:27,017 - INFO - --- Starting Data Loading and Preparation ---\n",
      "2025-05-02 10:44:27,090 - INFO - Successfully loaded dataset: flask_ml/data/Income_dataset.csv. Shape: (48842, 14)\n",
      "2025-05-02 10:44:27,212 - WARNING - Target values are binary but not 0/1 (['<=50K' '>50K']). Mapping first to 0, second to 1.\n",
      "2025-05-02 10:44:27,228 - INFO - Attempting to bin numeric column 'age' into 'age_bin'.\n",
      "2025-05-02 10:44:27,241 - INFO - Successfully binned 'age' into 'age_bin'. Unique values: ['35-44' '45-54' '25-34' '<25' '55-64' '65+']\n",
      "2025-05-02 10:44:27,241 - INFO - Protected attributes for analysis (column names): ['age_bin', 'race', 'sex']\n",
      "2025-05-02 10:44:27,242 - INFO - Identified 10 potential features for grid search.\n",
      "2025-05-02 10:44:27,268 - INFO - Final dataset shape before split: (48842, 15)\n",
      "2025-05-02 10:44:27,301 - INFO - Data split complete: Train size=39073, Test size=9769\n",
      "2025-05-02 10:44:27,353 - INFO - --- Starting Feature Subset Grid Search ---\n",
      "2025-05-02 10:44:27,354 - INFO - Generating feature combinations (Min Size: 1, Max Size: 9)...\n",
      "2025-05-02 10:44:27,354 - INFO - Added the full feature set (10 features).\n",
      "2025-05-02 10:44:27,355 - INFO - Total feature combinations to process: 1023\n",
      "2025-05-02 10:44:40,339 - INFO - --- Processing Combination 100/1023 (3 features) ---\n",
      "2025-05-02 10:44:59,480 - INFO - --- Processing Combination 200/1023 (4 features) ---\n",
      "2025-05-02 10:45:19,533 - INFO - --- Processing Combination 300/1023 (4 features) ---\n",
      "2025-05-02 10:45:39,059 - INFO - --- Processing Combination 400/1023 (5 features) ---\n",
      "2025-05-02 10:46:05,272 - INFO - --- Processing Combination 500/1023 (5 features) ---\n",
      "2025-05-02 10:46:31,534 - INFO - --- Processing Combination 600/1023 (5 features) ---\n",
      "2025-05-02 10:47:00,427 - INFO - --- Processing Combination 700/1023 (6 features) ---\n",
      "2025-05-02 10:47:30,783 - INFO - --- Processing Combination 800/1023 (6 features) ---\n",
      "2025-05-02 10:48:06,084 - INFO - --- Processing Combination 900/1023 (7 features) ---\n",
      "2025-05-02 10:48:46,141 - INFO - --- Processing Combination 1000/1023 (8 features) ---\n",
      "2025-05-02 10:48:56,865 - INFO - --- Processing Combination 1023/1023 (10 features) ---\n",
      "2025-05-02 10:48:57,378 - INFO - --- Grid Search Finished ---\n",
      "2025-05-02 10:48:57,378 - INFO - Processed 1023/1023 combinations.\n",
      "2025-05-02 10:48:57,379 - INFO - Total time: 270.02 seconds (4.50 minutes)\n",
      "2025-05-02 10:48:57,379 - INFO - --- Formatting and Saving Results ---\n",
      "2025-05-02 10:48:57,462 - INFO - Attempting to save results to: feature_gridsearch_fairness_results.xlsx\n",
      "2025-05-02 10:48:58,602 - INFO - Successfully saved results to feature_gridsearch_fairness_results.xlsx\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Results Summary (First 5 Rows) ---\n",
      "   Num Features  Accuracy  Demographic_Parity_Disparity_age_bin  \\\n",
      "0             1    0.6735                                0.2705   \n",
      "1             1    0.7130                                0.3002   \n",
      "2             1    0.7130                                0.3002   \n",
      "3             1    0.7172                                0.4282   \n",
      "4             1    0.6200                                0.1621   \n",
      "\n",
      "   Equalized_Odds_Disparity_age_bin  Predictive_Parity_Disparity_age_bin  \\\n",
      "0                            0.2222                               0.4374   \n",
      "1                            0.4247                               0.5694   \n",
      "2                            0.4247                               0.5694   \n",
      "3                            0.4626                               0.4684   \n",
      "4                            0.3032                               0.5350   \n",
      "\n",
      "   Demographic_Parity_Disparity_race  Equalized_Odds_Disparity_race  \\\n",
      "0                             0.1332                         0.2350   \n",
      "1                             0.2525                         0.4623   \n",
      "2                             0.2525                         0.4623   \n",
      "3                             0.1585                         0.5322   \n",
      "4                             0.1119                         0.3682   \n",
      "\n",
      "   Predictive_Parity_Disparity_race  Demographic_Parity_Disparity_sex  \\\n",
      "0                            0.2649                            0.1039   \n",
      "1                            0.1920                            0.0683   \n",
      "2                            0.1920                            0.0683   \n",
      "3                            0.3733                            0.3182   \n",
      "4                            0.2182                            0.0383   \n",
      "\n",
      "   Equalized_Odds_Disparity_sex  ...  Predictive_Parity_age_bin_5564  \\\n",
      "0                        0.0666  ...                          0.3592   \n",
      "1                        0.0517  ...                          0.5342   \n",
      "2                        0.0517  ...                          0.5342   \n",
      "3                        0.3818  ...                          0.4388   \n",
      "4                        0.1105  ...                          0.4527   \n",
      "\n",
      "  Predictive_Parity_age_bin_65plus  Predictive_Parity_age_bin_lt25  \\\n",
      "0                           0.2952                          0.0331   \n",
      "1                           0.4521                          0.0204   \n",
      "2                           0.4521                          0.0204   \n",
      "3                           0.3579                          0.0901   \n",
      "4                           0.3187                          0.0119   \n",
      "\n",
      "   Predictive_Parity_race_AmerIndianEskimo  \\\n",
      "0                                   0.1351   \n",
      "1                                   0.2500   \n",
      "2                                   0.2500   \n",
      "3                                   0.0882   \n",
      "4                                   0.1509   \n",
      "\n",
      "   Predictive_Parity_race_AsianPacIslander  Predictive_Parity_race_Black  \\\n",
      "0                                   0.3247                        0.1878   \n",
      "1                                   0.3988                        0.2526   \n",
      "2                                   0.3988                        0.2526   \n",
      "3                                   0.4392                        0.3711   \n",
      "4                                   0.3671                        0.1790   \n",
      "\n",
      "   Predictive_Parity_race_Other  Predictive_Parity_race_White  \\\n",
      "0                        0.4000                        0.3419   \n",
      "1                        0.3529                        0.4420   \n",
      "2                        0.3529                        0.4420   \n",
      "3                        0.3600                        0.4615   \n",
      "4                        0.2000                        0.3691   \n",
      "\n",
      "   Predictive_Parity_sex_Female  Predictive_Parity_sex_Male  \n",
      "0                        0.1788                      0.3774  \n",
      "1                        0.2270                      0.5196  \n",
      "2                        0.2270                      0.5196  \n",
      "3                        0.4486                      0.4526  \n",
      "4                        0.1614                      0.4552  \n",
      "\n",
      "[5 rows x 77 columns]\n",
      "\n",
      "--- Results Summary (Last 5 Rows) ---\n",
      "      Num Features  Accuracy  Demographic_Parity_Disparity_age_bin  \\\n",
      "1018             9    0.7992                                0.4186   \n",
      "1019             9    0.8028                                0.4226   \n",
      "1020             9    0.8034                                0.4213   \n",
      "1021             9    0.8034                                0.4224   \n",
      "1022            10    0.8028                                0.4224   \n",
      "\n",
      "      Equalized_Odds_Disparity_age_bin  Predictive_Parity_Disparity_age_bin  \\\n",
      "1018                            0.2727                               0.4219   \n",
      "1019                            0.2754                               0.4214   \n",
      "1020                            0.2726                               0.4248   \n",
      "1021                            0.2747                               0.4196   \n",
      "1022                            0.2781                               0.4060   \n",
      "\n",
      "      Demographic_Parity_Disparity_race  Equalized_Odds_Disparity_race  \\\n",
      "1018                             0.1651                         0.1852   \n",
      "1019                             0.1687                         0.1474   \n",
      "1020                             0.1699                         0.1484   \n",
      "1021                             0.1725                         0.1565   \n",
      "1022                             0.1672                         0.1484   \n",
      "\n",
      "      Predictive_Parity_Disparity_race  Demographic_Parity_Disparity_sex  \\\n",
      "1018                            0.3407                            0.2626   \n",
      "1019                            0.3239                            0.2575   \n",
      "1020                            0.3214                            0.2580   \n",
      "1021                            0.3654                            0.2580   \n",
      "1022                            0.3239                            0.2542   \n",
      "\n",
      "      Equalized_Odds_Disparity_sex  ...  Predictive_Parity_age_bin_5564  \\\n",
      "1018                        0.2211  ...                          0.5630   \n",
      "1019                        0.2135  ...                          0.5642   \n",
      "1020                        0.2134  ...                          0.5630   \n",
      "1021                        0.2163  ...                          0.5636   \n",
      "1022                        0.2099  ...                          0.5642   \n",
      "\n",
      "     Predictive_Parity_age_bin_65plus  Predictive_Parity_age_bin_lt25  \\\n",
      "1018                           0.5414                          0.2188   \n",
      "1019                           0.5414                          0.2203   \n",
      "1020                           0.5414                          0.2203   \n",
      "1021                           0.5464                          0.2241   \n",
      "1022                           0.5414                          0.2333   \n",
      "\n",
      "      Predictive_Parity_race_AmerIndianEskimo  \\\n",
      "1018                                   0.2308   \n",
      "1019                                   0.2500   \n",
      "1020                                   0.2500   \n",
      "1021                                   0.2500   \n",
      "1022                                   0.2500   \n",
      "\n",
      "      Predictive_Parity_race_AsianPacIslander  Predictive_Parity_race_Black  \\\n",
      "1018                                   0.5702                        0.5028   \n",
      "1019                                   0.5739                        0.5030   \n",
      "1020                                   0.5641                        0.5000   \n",
      "1021                                   0.5776                        0.5120   \n",
      "1022                                   0.5739                        0.4971   \n",
      "\n",
      "      Predictive_Parity_race_Other  Predictive_Parity_race_White  \\\n",
      "1018                        0.5714                        0.5573   \n",
      "1019                        0.5714                        0.5635   \n",
      "1020                        0.5714                        0.5648   \n",
      "1021                        0.6154                        0.5632   \n",
      "1022                        0.5714                        0.5638   \n",
      "\n",
      "      Predictive_Parity_sex_Female  Predictive_Parity_sex_Male  \n",
      "1018                        0.5174                      0.5583  \n",
      "1019                        0.5274                      0.5636  \n",
      "1020                        0.5275                      0.5644  \n",
      "1021                        0.5354                      0.5628  \n",
      "1022                        0.5238                      0.5642  \n",
      "\n",
      "[5 rows x 77 columns]\n"
     ]
    }
   ],
   "source": [
    "def create_preprocessing_pipeline(numericFeatures, categoricalFeatures):\n",
    "    \"\"\"Creates a ColumnTransformer pipeline for the given features.\"\"\"\n",
    "    transformers = []\n",
    "    if numericFeatures:\n",
    "        numPipe = Pipeline([\n",
    "            ('imp', SimpleImputer(strategy='mean')),\n",
    "            ('scale', StandardScaler())\n",
    "        ])\n",
    "        transformers.append(('num', numPipe, numericFeatures)) \n",
    "        \n",
    "    if categoricalFeatures:\n",
    "        catPipe = Pipeline([\n",
    "            ('imp', SimpleImputer(strategy='most_frequent')), \n",
    "            ('ohe', OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n",
    "        ])\n",
    "        transformers.append(('cat', catPipe, categoricalFeatures)) \n",
    "\n",
    "    if not transformers:\n",
    "        logging.warning(\"create_preprocessing_pipeline called with no features.\")\n",
    "        return ColumnTransformer(transformers=[], remainder='drop') \n",
    "\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=transformers,\n",
    "        remainder='drop', \n",
    "        verbose_feature_names_out=False \n",
    "    )\n",
    "    preprocessor.set_output(transform=\"pandas\") \n",
    "    return preprocessor\n",
    "\n",
    "# --- Data Loading and Preparation ---\n",
    "logging.info(\"--- Starting Data Loading and Preparation ---\")\n",
    "\n",
    "try:\n",
    "    dfFull = pd.read_csv(datasetPath)\n",
    "    logging.info(f\"Successfully loaded dataset: {datasetPath}. Shape: {dfFull.shape}\")\n",
    "except FileNotFoundError:\n",
    "    logging.error(f\"Dataset file not found at: {datasetPath}\")\n",
    "    raise\n",
    "except Exception as e:\n",
    "    logging.error(f\"Error loading dataset: {e}\")\n",
    "    raise\n",
    "\n",
    "dfFull.columns = dfFull.columns.str.strip()\n",
    "dfFull.columns = dfFull.columns.str.replace('-', '_', regex=False).str.replace(' ', '_', regex=False)\n",
    "\n",
    "for col in dfFull.select_dtypes(include=['object']).columns:\n",
    "    if col in dfFull.columns: \n",
    "        try:\n",
    "            dfFull[col] = dfFull[col].str.strip()\n",
    "            dfFull[col] = dfFull[col].replace(['?', 'N/A', '', 'None'], np.nan)\n",
    "        except AttributeError:\n",
    "            logging.warning(f\"Could not apply string operations to column '{col}'.\")\n",
    "\n",
    "essentialCols = [targetColumn] + protectedAttributesOriginal \n",
    "missingEssentials = [col for col in essentialCols if col not in dfFull.columns]\n",
    "if missingEssentials:\n",
    "    raise ValueError(f\"Essential columns missing from dataset: {missingEssentials}\")\n",
    "\n",
    "uniqueTargets = dfFull[targetColumn].unique()\n",
    "if len(uniqueTargets) > 2:\n",
    "    if '<=50K' in uniqueTargets and '>50K' in uniqueTargets:\n",
    "        targetMap = {'<=50K': 0, '>50K': 1}\n",
    "        dfFull[targetColumn] = dfFull[targetColumn].map(targetMap)\n",
    "    else:\n",
    "         if len(uniqueTargets) == 2:\n",
    "              logging.warning(f\"Target values not '<=50K', '>50K'. Using first unique value '{uniqueTargets[0]}' as 0, second '{uniqueTargets[1]}' as 1.\")\n",
    "              targetMap = {uniqueTargets[0]: 0, uniqueTargets[1]: 1}\n",
    "              dfFull[targetColumn] = dfFull[targetColumn].map(targetMap)\n",
    "         else:\n",
    "             raise ValueError(f\"Target column '{targetColumn}' has more than 2 unique values and standard mapping failed. Values: {uniqueTargets}\")\n",
    "elif len(uniqueTargets) == 1:\n",
    "     raise ValueError(f\"Target column '{targetColumn}' has only one unique value: {uniqueTargets[0]}. Cannot train a model.\")\n",
    "else: \n",
    "     if not set(uniqueTargets).issubset({0, 1}):\n",
    "         logging.warning(f\"Target values are binary but not 0/1 ({uniqueTargets}). Mapping first to 0, second to 1.\")\n",
    "         targetMap = {uniqueTargets[0]: 0, uniqueTargets[1]: 1}\n",
    "         dfFull[targetColumn] = dfFull[targetColumn].map(targetMap)\n",
    "\n",
    "if dfFull[targetColumn].isnull().any():\n",
    "    logging.warning(f\"Target column '{targetColumn}' contains NaN values after mapping. Checking count...\")\n",
    "    nanCount = dfFull[targetColumn].isnull().sum()\n",
    "    logging.warning(f\"{nanCount} rows have NaN target.\")\n",
    "    rowsBefore = len(dfFull)\n",
    "    dfFull.dropna(subset=[targetColumn], inplace=True)\n",
    "    logging.info(f\"Dropped {rowsBefore - len(dfFull)} rows with missing target values.\")\n",
    "    \n",
    "dfFull[targetColumn] = dfFull[targetColumn].astype(int)\n",
    "\n",
    "dfProcessed = apply_age_binning(dfFull, ageColumn, binnedAgeColumnName, defaultAgeBins, defaultAgeLabels)\n",
    "\n",
    "protectedAttributesAnalysis = [binnedAgeColumnName if p == ageColumn else p for p in protectedAttributesOriginal]\n",
    "logging.info(f\"Protected attributes for analysis (column names): {protectedAttributesAnalysis}\")\n",
    "\n",
    "potentialFeatureCols = [\n",
    "    col for col in dfProcessed.columns\n",
    "    if col != targetColumn and col not in protectedAttributesOriginal \n",
    "]\n",
    "if binnedAgeColumnName in potentialFeatureCols and binnedAgeColumnName != ageColumn:\n",
    "     potentialFeatureCols.remove(binnedAgeColumnName)\n",
    "\n",
    "logging.info(f\"Identified {len(potentialFeatureCols)} potential features for grid search.\")\n",
    "\n",
    "essentialAnalysisCols = [targetColumn] + protectedAttributesAnalysis \n",
    "rowsBeforeNa = len(dfProcessed)\n",
    "dfProcessed.dropna(subset=protectedAttributesAnalysis, inplace=True) \n",
    "rowsAfterNa = len(dfProcessed)\n",
    "if rowsAfterNa < rowsBeforeNa:\n",
    "    logging.warning(f\"Dropped {rowsBeforeNa - rowsAfterNa} rows due to missing values in protected attributes: {protectedAttributesAnalysis}\")\n",
    "\n",
    "if dfProcessed.empty:\n",
    "    raise ValueError(\"DataFrame is empty after handling missing values. Cannot proceed.\")\n",
    "\n",
    "logging.info(f\"Final dataset shape before split: {dfProcessed.shape}\")\n",
    "\n",
    "x = dfProcessed[potentialFeatureCols]\n",
    "y = dfProcessed[targetColumn]\n",
    "p = dfProcessed[protectedAttributesAnalysis] \n",
    "\n",
    "stratifyOption = y if y.nunique() > 1 and y.value_counts().min() >= 2 else None\n",
    "if stratifyOption is None:\n",
    "    logging.warning(\"Cannot stratify train/test split.\")\n",
    "    \n",
    "xTrainOrig, xTestOrig, yTrain, yTest, pTrain, pTest = train_test_split(\n",
    "    x, y, p,\n",
    "    test_size=testSize,\n",
    "    random_state=randomState,\n",
    "    stratify=stratifyOption\n",
    ")\n",
    "\n",
    "logging.info(f\"Data split complete: Train size={len(yTrain)}, Test size={len(yTest)}\")\n",
    "del dfFull, dfProcessed, x, y, p \n",
    "gc.collect()\n",
    "\n",
    "# --- Grid Search ---\n",
    "logging.info(\"--- Starting Feature Subset Grid Search ---\")\n",
    "startTimeGridsearch = time.time()\n",
    "\n",
    "allResults = []\n",
    "processedCombinationsCount = 0\n",
    "\n",
    "featureCombinations = []\n",
    "logging.info(f\"Generating feature combinations (Min Size: {minFeaturesCombinationSize}, Max Size: {maxFeaturesCombinationSize})...\")\n",
    "for k in range(minFeaturesCombinationSize, maxFeaturesCombinationSize + 1):\n",
    "    for combo in itertools.combinations(potentialFeatureCols, k): \n",
    "        featureCombinations.append(list(combo))\n",
    "\n",
    "if includeFullFeatureSet:\n",
    "    if tuple(potentialFeatureCols) not in [tuple(sorted(c)) for c in featureCombinations]: \n",
    "         featureCombinations.append(list(potentialFeatureCols))\n",
    "         logging.info(f\"Added the full feature set ({len(potentialFeatureCols)} features).\")\n",
    "         \n",
    "totalCombinations = len(featureCombinations)\n",
    "logging.info(f\"Total feature combinations to process: {totalCombinations}\")\n",
    "\n",
    "# --- Loop Through Combinations ---\n",
    "for i, selectedFeatures in enumerate(featureCombinations):\n",
    "    iterationStartTime = time.time()\n",
    "    if (i + 1) % logProgressEveryN == 0 or (i + 1) == totalCombinations:\n",
    "         logging.info(f\"--- Processing Combination {i+1}/{totalCombinations} ({len(selectedFeatures)} features) ---\")\n",
    "\n",
    "    if not all(f in xTrainOrig.columns for f in selectedFeatures): \n",
    "        logging.error(f\"Skipping combination {i+1}: Features not found in xTrainOrig. Features: {selectedFeatures}\")\n",
    "        continue\n",
    "        \n",
    "    xTrainSubset = xTrainOrig[selectedFeatures].copy()\n",
    "    xTestSubset = xTestOrig[selectedFeatures].copy()\n",
    "\n",
    "    numericFeaturesSubset = xTrainSubset.select_dtypes(include=np.number).columns.tolist()\n",
    "    categoricalFeaturesSubset = xTrainSubset.select_dtypes(exclude=np.number).columns.tolist()\n",
    "    \n",
    "    resultsRow = {\n",
    "        'Features Used': \", \".join(selectedFeatures), \n",
    "        'Num Features': len(selectedFeatures),      \n",
    "        'Accuracy': np.nan,                        \n",
    "    }\n",
    "    \n",
    "    for paColName in protectedAttributesAnalysis: \n",
    "        for metric in metricsForOverallDisparity:\n",
    "             key = f\"{metric.replace(' ', '_')}_Disparity_{paColName}\" \n",
    "             resultsRow[key] = np.nan\n",
    "\n",
    "    for paColName in protectedAttributesAnalysis: \n",
    "        for group in pTest[paColName].unique(): \n",
    "             groupStr = str(group) if pd.notna(group) else \"NaN_Group\" \n",
    "             groupStrKey = groupStr.replace('<','lt').replace('+','plus').replace(' ','_').replace('=','eq')\n",
    "             groupStrKey = ''.join(filter(lambda x: x.isalnum() or x == '_', groupStrKey))\n",
    "             for fm in fairnessMetricsSubgroup:\n",
    "                fmKeyPart = fm.replace(' ', '_')\n",
    "                key = f\"{fmKeyPart}_{paColName}_{groupStrKey}\" \n",
    "                resultsRow[key] = np.nan \n",
    "    \n",
    "    # --- Main Processing Logic ---\n",
    "    try:\n",
    "        preprocessor = create_preprocessing_pipeline(numericFeaturesSubset, categoricalFeaturesSubset)\n",
    "        xTrainProcessed = preprocessor.fit_transform(xTrainSubset)\n",
    "        xTestProcessed = preprocessor.transform(xTestSubset)\n",
    "\n",
    "        model = LogisticRegression(**lrParams) \n",
    "        if xTrainProcessed.shape[1] == 0:\n",
    "             # Log warning only if it happens\n",
    "             logging.warning(f\"Combination {i+1} resulted in 0 features after preprocessing. Skipping training. Features: {selectedFeatures}\")\n",
    "             yPred = np.repeat(yTrain.mode()[0], len(yTest)) \n",
    "        else:\n",
    "            model.fit(xTrainProcessed, yTrain) \n",
    "            yPred = model.predict(xTestProcessed)\n",
    "\n",
    "        accuracy = accuracy_score(yTest, yPred) \n",
    "        resultsRow['Accuracy'] = round(accuracy, 4) \n",
    "\n",
    "        # --- Evaluation: Fairness ---\n",
    "        resultsDfTemp = pTest.copy() \n",
    "        resultsDfTemp['y_true'] = yTest \n",
    "        resultsDfTemp['y_pred'] = yPred\n",
    "\n",
    "        allSubgroupMetrics = {} \n",
    "\n",
    "        for paColName in protectedAttributesAnalysis: \n",
    "            subgroupMetricsForPa = {} \n",
    "            metricsForDisparityCalc = {m: [] for m in ['Demographic Parity', 'Equalized Odds', 'FPR', 'Predictive Parity']} \n",
    "\n",
    "            uniqueGroups = resultsDfTemp[paColName].unique() \n",
    "            \n",
    "            for groupName in uniqueGroups:\n",
    "                 groupNameStr = str(groupName) if pd.notna(groupName) else \"NaN_Group\" \n",
    "                 \n",
    "                 groupDf = resultsDfTemp[resultsDfTemp[paColName] == groupName]\n",
    "                 metrics = calculate_fairness_metrics(groupDf) \n",
    "                 subgroupMetricsForPa[groupNameStr] = metrics\n",
    "                 \n",
    "                 groupStrKey = groupNameStr.replace('<','lt').replace('+','plus').replace(' ','_').replace('=','eq')\n",
    "                 groupStrKey = ''.join(filter(lambda x: x.isalnum() or x == '_', groupStrKey))\n",
    "                 for fmKey, fmValue in metrics.items():\n",
    "                      fmKeyPart = fmKey.replace(' ', '_')\n",
    "                      colNameKey = f\"{fmKeyPart}_{paColName}_{groupStrKey}\" \n",
    "                      \n",
    "                      if colNameKey in resultsRow:\n",
    "                          resultsRow[colNameKey] = round(fmValue, 4) if pd.notna(fmValue) else np.nan\n",
    "                      else:\n",
    "                          logging.warning(f\"Adding new results column key dynamically (unexpected): {colNameKey}\")\n",
    "                          resultsRow[colNameKey] = round(fmValue, 4) if pd.notna(fmValue) else np.nan\n",
    "\n",
    "                 if metrics['Group Size'] > 0:\n",
    "                      for metricKeyInternal in metricsForDisparityCalc.keys():\n",
    "                           if pd.notna(metrics[metricKeyInternal]): \n",
    "                               metricsForDisparityCalc[metricKeyInternal].append(metrics[metricKeyInternal])\n",
    "            \n",
    "            allSubgroupMetrics[paColName] = subgroupMetricsForPa \n",
    "            \n",
    "            # --- Calculate Overall Disparity Scores ---\n",
    "            for metricDisp in metricsForOverallDisparity: \n",
    "                overallScore = np.nan\n",
    "                \n",
    "                if metricDisp == 'Equalized Odds':\n",
    "                     tprRates = metricsForDisparityCalc.get('Equalized Odds', []) \n",
    "                     fprRates = metricsForDisparityCalc.get('FPR', [])\n",
    "                     tprDiff = max(tprRates) - min(tprRates) if len(tprRates) > 1 else 0.0\n",
    "                     fprDiff = max(fprRates) - min(fprRates) if len(fprRates) > 1 else 0.0\n",
    "                     validDiffs = [d for d in [tprDiff, fprDiff] if pd.notna(d)]\n",
    "                     overallScore = max(validDiffs) if validDiffs else np.nan\n",
    "                else:\n",
    "                     rates = metricsForDisparityCalc.get(metricDisp, [])\n",
    "                     if len(rates) > 1:\n",
    "                         overallScore = max(rates) - min(rates)\n",
    "                     \n",
    "                disparityKey = f\"{metricDisp.replace(' ', '_')}_Disparity_{paColName}\" \n",
    "                resultsRow[disparityKey] = round(overallScore, 4) if pd.notna(overallScore) else np.nan\n",
    "                \n",
    "        processedCombinationsCount += 1\n",
    "\n",
    "    except MemoryError:\n",
    "        logging.error(f\"Memory Error encountered processing combination {i+1}. Skipping.\")\n",
    "        gc.collect() \n",
    "        resultsRow['Accuracy'] = 'Memory Error' \n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error processing combination {i+1} ({selectedFeatures}): {e}\", exc_info=True) \n",
    "        resultsRow['Accuracy'] = f'Error: {type(e).__name__}' \n",
    "\n",
    "    finally:\n",
    "        allResults.append(resultsRow)\n",
    "        del xTrainSubset, xTestSubset \n",
    "        if 'xTrainProcessed' in locals(): del xTrainProcessed\n",
    "        if 'xTestProcessed' in locals(): del xTestProcessed\n",
    "        if 'model' in locals(): del model\n",
    "        if 'preprocessor' in locals(): del preprocessor\n",
    "        if 'resultsDfTemp' in locals(): del resultsDfTemp \n",
    "\n",
    "\n",
    "\n",
    "gridsearchDuration = time.time() - startTimeGridsearch\n",
    "logging.info(f\"--- Grid Search Finished ---\")\n",
    "logging.info(f\"Processed {processedCombinationsCount}/{totalCombinations} combinations.\")\n",
    "logging.info(f\"Total time: {gridsearchDuration:.2f} seconds ({gridsearchDuration/60:.2f} minutes)\")\n",
    "\n",
    "\n",
    "# --- Formatting and Saving Results ---\n",
    "logging.info(\"--- Formatting and Saving Results ---\")\n",
    "\n",
    "if not allResults:\n",
    "    logging.warning(\"No results were generated. Skipping saving to Excel.\")\n",
    "else:\n",
    "    resultsDf = pd.DataFrame(allResults) \n",
    "    \n",
    "    colsOrder = ['Num Features', 'Accuracy'] \n",
    "    for paColName in protectedAttributesAnalysis:\n",
    "        for metric in metricsForOverallDisparity:\n",
    "            colsOrder.append(f\"{metric.replace(' ', '_')}_Disparity_{paColName}\")\n",
    "            \n",
    "    colsOrder.append('Features Used') \n",
    "    \n",
    "    remainingCols = [col for col in resultsDf.columns if col not in colsOrder]\n",
    "    remainingCols.sort() \n",
    "    \n",
    "    finalCols = colsOrder + remainingCols\n",
    "    finalCols = [col for col in finalCols if col in resultsDf.columns]\n",
    "    \n",
    "    resultsDf = resultsDf[finalCols]\n",
    "\n",
    "    try:\n",
    "        logging.info(f\"Attempting to save results to: {outputExcelFile}\")\n",
    "        resultsDf.to_excel(outputExcelFile, index=False, engine='openpyxl')\n",
    "        logging.info(f\"Successfully saved results to {outputExcelFile}\")\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Failed to save results to Excel: {e}\", exc_info=True)\n",
    "        try:\n",
    "             csvFallbackPath = outputExcelFile.replace('.xlsx', '.csv')\n",
    "             logging.warning(f\"Saving results as CSV fallback: {csvFallbackPath}\")\n",
    "             resultsDf.to_csv(csvFallbackPath, index=False)\n",
    "             logging.info(f\"Successfully saved results to {csvFallbackPath}\")\n",
    "        except Exception as csvE:\n",
    "             logging.error(f\"Failed to save results to CSV as fallback: {csvE}\", exc_info=True)\n",
    "\n",
    "#\n",
    "print(\"\\n--- Results Summary (First 5 Rows) ---\")\n",
    "print(resultsDf.head())\n",
    "print(\"\\n--- Results Summary (Last 5 Rows) ---\")\n",
    "print(resultsDf.tail())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
